\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{EvaluaciÃ³n 1 - AnÃ¡lisis Cuantitativo}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \emph{Luisa Fernanda Giraldo }

\emph{Juan Sebastian Guzman }

     \textbf{IntroducciÃ³n}

Como parte del ejercicio profesional de los cientÃ­ficos de datos, los
modelos de aprendizaje supervisado estÃ¡n siempre presentes. Dentro de
estos, los modelos de regresiÃ³n lineal han representado una herramienta
poderosa para comprender la relaciÃ³n entre fenÃ³menos y predecir sucesos,
agragando valor a travÃ©s de la manera en la que ofrece informaciÃ³n para
la toma de decisiones y la gestiÃ³n de los negocios. Este trabajo se
propone reforzar los conceptos de regresiÃ³n lineal y afinar las
habilidades de sus autores como cientÃ­ficos de datos, convirtiÃ©ndose en
una oportunidad para afianzar conceptos y ponerlos en prÃ¡ctica para
nuestro futuro como profesionales en el campo. Abordaremos modelos de
regresiÃ³n lineal simple con y sin interacciÃ³n asÃ­ como modelos de
regresiÃ³n mÃºltiple; hallamos los resultados a travÃ©s de paquetes
estadÃ­sticos de python asÃ­ la aproximaciÃ³n matricial a los cÃ¡lculos de
los parÃ¡metros. Por Ãºltimo, discutiremos conceptualmente sobre el modelo
de regresiÃ³n logÃ­stica.

\textbf{Conceptos Claves}: Modelo de regresion lineal, regresiÃ³n lineal
mÃºltiple, prueba de hipÃ³tesis, regresiÃ³n robusta, modelo con
interacciÃ³n, regresiÃ³n logÃ­stica.

 \textbf{Summary}

Supervised learning models are always present in the daily lives of data
scientists. Within these, linear regression models have represented a
powerful tool for understanding the relationship between phenomena and
predicting events, adding value by providing information for decision
making and business management. This paper aims to reinforce the
concepts of linear regression and sharpen the authors' skills as data
scientists, becoming an opportunity to strengthen concepts and put them
into practice for our future as professionals in the field. We will
cover simple linear regression models with and without interaction as
well as multiple regression models; we will find the results through
Python statistical packages as well as the matrix approach to parameter
calculations. Lastly, we wil conceptually discuss the logistic
regression prediction approach.

\textbf{Key terms}: Linear regression, multiple linear regression,
hypothesis tests, robust regression, interaction model, log-linear
regression.

    Iniciamos importando las librerÃ­as necesarias para la resoluciÃ³n de los
ejercicios propuestos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{228}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Importamos librerias necesarias}

\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sn}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Scaler estandar}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}

\PY{c+c1}{\PYZsh{} Splitter para partir el dataset en entrenamiento/prueba}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{ejercicio-de-regresiuxf3n-lineal-con-interacciuxf3n}{%
\subsubsection{Ejercicio de regresiÃ³n lineal con
interacciÃ³n}\label{ejercicio-de-regresiuxf3n-lineal-con-interacciuxf3n}}

    Procedemos a importar nuestro primer set de datos, con el que
abordaremos el primer apartado de este documento.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{229}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Importar el data set}
\PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{D:}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{OneDrive \PYZhy{} Tecnoquimicas}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{99. PERSONAL}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{FormaciÃ³n}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Maestria}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Semestre 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Analisis Cuantitivo}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Trabajo 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{data\PYZus{}exam1.xlsx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{sheet\PYZus{}name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Continuamos con el anÃ¡lisis exploratorio, entendiendo la estructura del
data set, estadÃ­sticas descriptivas de las variables y adelantando el
anÃ¡lisis grÃ¡fico.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{230}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Se visualiza la estructura del dataset}
\PY{n}{df}\PY{o}{.}\PY{n}{shape}
\PY{n}{df}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 \#   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   Y       1000 non-null   float64
 1   X       1000 non-null   float64
 2   Ind     1000 non-null   int64
dtypes: float64(2), int64(1)
memory usage: 23.6 KB
    \end{Verbatim}

    Se evidencia que no existen datos nulos para ninguan de las variables
del dataset. AdemÃ¡s, existen dos variables que toman valores decimales
\textbf{``X''} \& \textbf{``Y''}, y la variable \textbf{``Ind''} que
toma valores enteros. Procedemos a calcular las estadÃ­sticas
descriptivas para el dataset.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{231}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Se calculan las estadÃ­sticas }
\PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{231}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                 Y            X        Ind
count  1000.000000  1000.000000  1000.0000
mean     46.953751     9.976858     0.2000
std      22.046143     3.762567     0.4002
min     -34.894319    -4.263757     0.0000
25\%      32.427643     7.638899     0.0000
50\%      45.460252     9.952888     0.0000
75\%      61.587567    12.379984     0.0000
max     135.542574    25.628678     1.0000
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{232}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Valores que puede tomar la variable Ind}
\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{232}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([0, 1], dtype=int64)
\end{Verbatim}
\end{tcolorbox}
        
    Nos damos cuenta que \textbf{``Ind''} es una variable categÃ³rica
binaria, es decir, toma valores entre 0 \& 1. Procedemos a graficar la
matriz de dispersiÃ³n para revisar graficamente la relaciÃ³n entre las
variables.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{233}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sn}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_13_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{234}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}OrdenaciÃ³n de los grÃ¡ficos espacialmente en una matriz}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{sn}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Boxplot de la variable X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
\PY{n}{sn}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de la variable Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Seteo del estilo de los grÃ¡ficos}
\PY{n}{sn}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkgrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_14_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{235}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}GrÃ¡fico de dispersiÃ³n con linea de regresiÃ³n}
\PY{n}{sn}\PY{o}{.}\PY{n}{lmplot}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{df}\PY{p}{,} \PY{n}{x}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{line\PYZus{}kws}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{color}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{aspect}\PY{o}{=}\PY{l+m+mi}{7}\PY{o}{/}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{palette}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mako}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{235}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<seaborn.axisgrid.FacetGrid at 0x14d927e9790>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al graficar las dos atributos, evidenciamos que para la variable
\textbf{`X'} existen un buen nÃºmero de valores atÃ­picos, tanto positivos
como negativos; sin embargo, no parece presentar un sesgo significativo
en la distribuciÃ³n de los datos, acercÃ¡ndose a una distribuciÃ³n normal.
Por otro lado, para la variable \textbf{`Ind'} vemos que es 4 veces el
nÃºmero de registros que reportan 0 para esta variable que los que
reportan 1.

Al graficar la relaciÃ³n entre las variables evidenciamos una
distribuciÃ³n de las observaciones similar a una elipse, lo que
preliminarmente nos llevarÃ­a a creer que existe una relaciÃ³n lineal
positiva entre las variables, por lo podrÃ­amos plantear el uso de un
modelo de regresiÃ³n lineal para explicar y predecir el comportamiento de
Y en funciÃ³n de X. podrÃ­amos

    Ahora, debido a que los posible valores que toma la variable
\textbf{`Ind'} son (0,1), asumimos que estamos lidiando con una variable
categÃ³rica de dos niveles, por lo que podrÃ­amos correr un modelo de
regresiÃ³n mÃºltiple, con la variable \textbf{`Ind'} como segunda variable
predictora, tal que se plantea el modelo

\[ \begin{align} 
y = \beta_0 + \beta_1X + \beta_2Ind + \epsilon = \left\{ 
    \begin{array}{ll}  \beta_0 + \beta_1X + \beta_2 + \epsilon & \text{si  Ind = 1} \\ 
    \beta_0 + \beta_1X + \epsilon & \text {si  Ind = 0} \end{array} \right. \end{align} \]

AsÃ­, podemos definir \(\beta_1\) como el cambio medio de la variable Y
por un cambio unitario de X, con todas las demÃ¡s variables constantes;
igualmente, podemos definir \(\beta_2\) como a la agregaciÃ³n al valor
medio de Y cuando Ind toma el valor de 1.

Procedemos a correr el modelo:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{236}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{x} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{}Apartar variables dependientes + constante}
\PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{c+c1}{\PYZsh{} Variable independiente }

\PY{c+c1}{\PYZsh{}Modelados}
\PY{n}{model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y}\PY{p}{,}\PY{n}{x}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Hacemos fit al modelo e imprimimos los resultados}
\PY{n}{results} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{results}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:                      Y   R-squared:                       0.759
Model:                            OLS   Adj. R-squared:                  0.758
Method:                 Least Squares   F-statistic:                     1566.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):          2.25e-308
Time:                        19:33:17   Log-Likelihood:                -3801.1
No. Observations:                1000   AIC:                             7608.
Df Residuals:                     997   BIC:                             7623.
Df Model:                           2
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
X              4.9116      0.091     53.848      0.000       4.733       5.091
Ind          -14.1796      0.858    -16.535      0.000     -15.862     -12.497
const          0.7873      0.984      0.800      0.424      -1.143       2.718
==============================================================================
Omnibus:                        2.517   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.284   Jarque-Bera (JB):                2.440
Skew:                           0.078   Prob(JB):                        0.295
Kurtosis:                       3.185   Cond. No.                         31.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    Al correr el OLS, nos encontramos con que el modelo lineal ajusta un
75.8\% los datos, con un p\_value \textless{} 0.05 que nos asegura la
significancia del modelo. Los resultados arrojados por el modelo nos
permite plantear el modelo

\[ \hat{Y} = \left\{ 
    \begin{array}{ll} (0.7873-14.1796) + 4.9116X & \text{si  Ind = 1} \\
    \ (0.7873) + 4.9116X & \text {si  Ind = 0} \end{array} \right. \]

Donde cada coeficiente lo podemos interpretar:

\[ \hat{\beta_{0}} = 0.7873 \text{ como intercepto. Es valor medio de } \hat{Y} \text{ cuando las demÃ¡s variables toman valor de 0} \]
\[ \hat{\beta_{1}} = 4.9116 \text{ Ante un cambio en 1 unidad de la variable X, el valor esperado de Y aumentarÃ­a 4.9116 } \\ \text{dejando todas las demÃ¡s variables constantes. Es significativo con un p-value < 0.05} \]
\[ \hat{\beta_{2}} = -14.1796. \text{ El valor medio de } \hat{Y} \text{ se reduce en -14.1769 si el individuo registra una valor de 1 en la variable Ind, independientemente del valor que tome X.}\\
\text{Es decir, para los individuos con Ind = 1, el valor esperado medio de Y serÃ¡ de -13.3923 si X tomarÃ¡ el valor de 0}\]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{237}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}GrÃ¡fico de dispersiÃ³n con linea de regresiÃ³n segÃºn el valor que tome Ind}

\PY{n}{sn}\PY{o}{.}\PY{n}{lmplot}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{line\PYZus{}kws}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{color}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{aspect}\PY{o}{=}\PY{l+m+mi}{7}\PY{o}{/}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{palette}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mako}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{237}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<seaborn.axisgrid.FacetGrid at 0x14d976db400>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al realizar el grÃ¡fico de dispersiÃ³n diferenciando cada punto por la
variable \textbf{`Ind'} evidenciamos que para ambos casos (0,1) parece
existir una relaciÃ³n de dependencia positiva, sin embargo, los
individuos cuyo atributo Ind = 1 parecen reportar valores de Y menores
que los aquellos con Ind = 0, lo cual es coherente con lo visto en el
modelo anterior (con \(\beta_2 = -14.1796\)). Debido a que el modelo
anterior nos arrojÃ³ que la variable categÃ³rica es significativa para el
modelo, podemos pensar en correr un modelo con interacciÃ³n entre las
variables \textbf{`X'} e \textbf{`Ind'}, que lo podemos plantear como:

\[ \begin{align} 
\hat{y} = \hat{\beta_0} + \hat{\beta_1}X + \hat{\beta_2}Ind + \hat{\beta_3}*X*Ind = \left\{ 
    \begin{array}{ll}  (\hat{\beta_0} +  \hat{\beta_2})+ (\hat{\beta_1} + \hat{\beta_3})X & \text{si  Ind = 1} \\ 
    \hat{\beta_0} + \hat{\beta_1}X & \text {si  Ind = 0} \end{array} \right. \end{align} \]

El planteamiento de este modelo nos muestra no solo un cambio en el
intercepto sino tambiÃ©n un cambio en la pendiente del modelo, de manera
que nos permita probar si ante un cambio en 1 unidad de X, esta variable
termina afectando de manera distinta a los individuos dependiendo del
valor que tome la variable \textbf{`Ind'}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{238}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Generamos la variable interacciÃ³n}
\PY{n}{interaccion} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{*}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Interaccion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{interaccion}

\PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{238}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
           Y          X  Ind  Interaccion
0  66.199147  12.653765    0     0.000000
1  44.311301   8.204418    0     0.000000
2  48.390783   8.768596    0     0.000000
3  58.087413  16.169568    1    16.169568
4  60.708671   9.980310    0     0.000000
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{239}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Corremos el modelo con la interacciÃ³n}
\PY{n}{x\PYZus{}inter} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Interaccion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}inter} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{}Modelamos}
\PY{n}{model\PYZus{}inter} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y\PYZus{}inter}\PY{p}{,}\PY{n}{x\PYZus{}inter}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Hacemos fit e imprimimos resultados}
\PY{n}{results\PYZus{}inter} \PY{o}{=} \PY{n}{model\PYZus{}inter}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{results\PYZus{}inter}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:                      Y   R-squared:                       0.765
Model:                            OLS   Adj. R-squared:                  0.764
Method:                 Least Squares   F-statistic:                     1081.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):          1.34e-312
Time:                        19:33:18   Log-Likelihood:                -3787.5
No. Observations:                1000   AIC:                             7583.
Df Residuals:                     996   BIC:                             7603.
Df Model:                           3
Covariance Type:            nonrobust
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
X               5.0411      0.093     53.997      0.000       4.858       5.224
Ind             4.5491      3.674      1.238      0.216      -2.661      11.759
Interaccion    -1.8466      0.353     -5.239      0.000      -2.538      -1.155
const          -0.4991      1.001     -0.498      0.618      -2.464       1.466
==============================================================================
Omnibus:                        4.301   Durbin-Watson:                   1.985
Prob(Omnibus):                  0.116   Jarque-Bera (JB):                4.811
Skew:                           0.065   Prob(JB):                       0.0902
Kurtosis:                       3.314   Cond. No.                         119.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    Al correr el modelo con la interacciÃ³n evidenciamos que el ajuste del
modelo mejora, pasando de un 75.8\% a 76.4\% con un p\_value del modelo
menor a 0.05. Sin embargo, vemos que la variable de Ind que en el modelo
anterior era significativa deja de tener significancia y, en cambio, la
la interacciÃ³n entre las dos variable cuenta con un
p\_value\textless0.05. Volvemos a correr el modelo sin la variable Ind y
revisamos sus resultados

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{240}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Corremos el modelo con la interacciÃ³n eliminando la variable categÃ³rica Ind como predictor solo}
\PY{n}{x\PYZus{}inter2} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Interaccion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}inter2} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{model\PYZus{}inter2} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y\PYZus{}inter2}\PY{p}{,}\PY{n}{x\PYZus{}inter2}\PY{p}{)}

\PY{n}{results\PYZus{}inter2} \PY{o}{=} \PY{n}{model\PYZus{}inter2}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{results\PYZus{}inter2}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:                      Y   R-squared:                       0.765
Model:                            OLS   Adj. R-squared:                  0.764
Method:                 Least Squares   F-statistic:                     1620.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):          6.34e-314
Time:                        19:33:18   Log-Likelihood:                -3788.2
No. Observations:                1000   AIC:                             7582.
Df Residuals:                     997   BIC:                             7597.
Df Model:                           2
Covariance Type:            nonrobust
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
X               5.0120      0.090     55.465      0.000       4.835       5.189
Interaccion    -1.4219      0.081    -17.504      0.000      -1.581      -1.263
const          -0.1611      0.964     -0.167      0.867      -2.052       1.730
==============================================================================
Omnibus:                        3.980   Durbin-Watson:                   1.986
Prob(Omnibus):                  0.137   Jarque-Bera (JB):                4.433
Skew:                           0.057   Prob(JB):                        0.109
Kurtosis:                       3.306   Cond. No.                         31.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    Al correr nuevamente el modelo sin la variable \textbf{`Ind'} vemos que
no hay un cambio en el porcentaje de ajuste, sin embargo, nos deshacemos
de variables que no son significativas para el modelo. Por lo mismo, se
puede concluir que la interacciÃ³n entre la variable \textbf{`Ind'} \&
\textbf{`X'} nos conduce generar un modelo que explica y predice de
mejor manera los valores de Y. Por tanto, planteamos el modelo e
interpretamos los coeficientes.

\[ \begin{align} 
\hat{y} = \hat{\beta_0} + \hat{\beta_1}X + \hat{\beta_3}*X*Ind = \left\{ 
    \begin{array}{ll} \hat{\beta_0}+ (\hat{\beta_1} + \hat{\beta_3})X & \text{si  Ind = 1} \\ 
    \hat{\beta_0} + \hat{\beta_1}X & \text {si  Ind = 0} \end{array} \right. \end{align} \]

\[ \begin{align} 
 = -0.1611 + 5.0120*X + -1.4219*X*Ind = \left\{ 
    \begin{array}{ll} -0.1611+ 3.5901*X & \text{si  Ind = 1} \\ 
    -0.1611 + 5.0120*X & \text {si  Ind = 0} \end{array} \right. \end{align} \]

    De esta manera, podemos concluir que ante un cambio unitario en X el
impacto medio en Y es distinto dependiendo del valor que tome la
variable \textbf{`Ind'}. AsÃ­,

\[ 
\hat{\beta_1} : 5.0120. \text{ y aumenta en promedio 5.0120 cuando X cambia en una unidad, dado si la variable Ind toma el valor de 0} \\
(\hat{\beta_1} + \hat{\beta_3}) : 3.5901. \text{ y aumenta en promedio 3.5901 cuando X cambia en una unidad, siempre que la variable Ind tome valor 1}
\]

Es decir, los individuos que reportan 1 en el atributo indicador
perciben un menor impacto ante cambios en X que aquellos que tiene 0
asignado. No hay cambios en el intercepto, pues la variable Ind por sÃ­
sola no es significativa para el modelo.

    \hypertarget{prueba-de-supuestos-del-modelo}{%
\paragraph{Prueba de supuestos del
modelo}\label{prueba-de-supuestos-del-modelo}}

Una vez planteado el modelo, procedemos a validar cada uno de los
supuestos del modelo.

\[ \epsilon_i \overset{iid}\sim N(0, \sigma^2) \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Independencia de los errores
\end{enumerate}

\[ H_0: \rho(\epsilon_{i}, \epsilon_{i+1}) = 0 \\
H_1: \rho(\epsilon_{i}, \epsilon_{i+1}) \neq 0 \]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{241}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{tsaplots} \PY{k+kn}{import} \PY{n}{plot\PYZus{}acf}\PY{p}{,} \PY{n}{plot\PYZus{}pacf}

\PY{c+c1}{\PYZsh{} Test grafico de autocorrelaciones}
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{plot\PYZus{}acf}\PY{p}{(}\PY{n}{y\PYZus{}inter2}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{lags}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ACF de la variable Y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}
\PY{n}{plot\PYZus{}pacf}\PY{p}{(}\PY{n}{y\PYZus{}inter2}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{lags}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PACF de la variable Y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}

\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{1.2}\PY{p}{]}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{1.2}\PY{p}{]}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplots\PYZus{}adjust}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_29_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al construir el grafico de autocorrelaciÃ³n simple y autocorrelaciÃ³n
parcial de la variable dependiente, aparentemente vemos que, con un lag
de 5 datos, solo el primero es significativo y nos llevarÃ­a a pensar que
existe independencia de los errores. AdemÃ¡s, al correr el modelo nos
arroja un valor de Durbin - Watson de 1.986, muy cerca del 2 ideal, lo
que nos reforzarÃ­a la idea de no autocorrelaciÃ³n.

Corremos la prueba de Breusch - Godfrey definiendo el mÃ©todo y
presentando una tabla de validaciÃ³n de hipÃ³tesis, que se definen asÃ­:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{242}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{diagnostic} \PY{k+kn}{import} \PY{n}{acorr\PYZus{}breusch\PYZus{}godfrey}\PY{p}{,} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{,} \PY{n}{het\PYZus{}white}

\PY{c+c1}{\PYZsh{} Test Breusch Godfrey}
\PY{k}{def} \PY{n+nf}{test\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{model\PYZus{}results}\PY{p}{,} \PY{n}{maxlags}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{list} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{maxlags}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        \PY{n}{values} \PY{o}{=} \PY{n}{acorr\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{model\PYZus{}results}\PY{p}{,} \PY{n}{nlags}\PY{o}{=}\PY{n}{i}\PY{p}{)}
        \PY{n+nb}{list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{values}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
    
    \PY{n}{table} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n+nb}{list}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lags}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{table}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lags}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} P\PYZhy{}value \PYZlt{} pvalue }
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.1}
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.05}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.05}
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.01}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.01}

    \PY{c+c1}{\PYZsh{} Rounding}
    \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

    \PY{k}{return} \PY{n}{table}


\PY{c+c1}{\PYZsh{} La hipotesis nula es de no autocorrelacion}
\PY{c+c1}{\PYZsh{} Se rechaza la no autocorrelacion hasta 3 rezagos. }
\PY{n}{test\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{results\PYZus{}inter2}\PY{p}{,} \PY{n}{maxlags}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{242}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
         LM  pvalue  pv<0.1  pv<0.05  pv<0.01
lags
1     0.050   0.823   False    False    False
2     1.864   0.394   False    False    False
3     3.396   0.335   False    False    False
\end{Verbatim}
\end{tcolorbox}
        
    Al correr el test de Breusch - Godfrey hasta en 3 rezagos podemos
aceptar la hipÃ³tesis nula y concluir que los errores son independiente,
por lo mismo no existe evidencia de \textbf{autocorrelaciÃ³n}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Continuamos con validaciÃ³n de la varianza constante de los errores.
\end{enumerate}

\[ H_0: \mathbb{V}(\epsilon_{i}) = Constante \\
H_1: \mathbb{V}(\epsilon_{i})  \neq Constante \]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{243}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Test grÃ¡fico}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{results\PYZus{}inter2}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}inter2}\PY{p}{)}
\PY{n}{resid} \PY{o}{=} \PY{n}{results\PYZus{}inter2}\PY{o}{.}\PY{n}{resid}

\PY{n}{sn}\PY{o}{.}\PY{n}{scatterplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{y\PYZus{}hat}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{resid}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Analisis grafico de los residuos}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fuerza de compresiÃ³n del concreto}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Residuo}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{243}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Text(0, 0.5, 'Residuo')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_33_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{244}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Test Breusch \PYZhy{} Pagan}
\PY{n}{BP\PYZus{}test} \PY{o}{=} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{(}\PY{n}{resid}\PY{p}{,} \PY{n}{results\PYZus{}inter2}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{BP\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{BP\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{El estadistico Breusch \PYZhy{} Pagan es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ y el p\PYZhy{}value es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Test de White}
\PY{n}{white\PYZus{}test} \PY{o}{=} \PY{n}{het\PYZus{}white}\PY{p}{(}\PY{n}{resid}\PY{p}{,} \PY{n}{results\PYZus{}inter2}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EstadÃ­stico White}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Statistic}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Test p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{white\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{white\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{white\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
El estadistico Breusch - Pagan es 80.02 y el p-value es 0.0
\{'EstadÃ­stico White': 83.151, 'p-value': 0.0, 'F-Statistic': 22.56, 'F-Test
p-value': 0.0\}
    \end{Verbatim}

    Ambas pruebas nos dan un p-value menor a 0.05, lo que nos lleva a
rechazar la hipÃ³tesis nula y concluir que el modelo presenta
heterocedasticidad, es decir, la varianza de los errores no es
constante.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Errores se distribuyen de manera normal. Adelantamos anÃ¡lisis grÃ¡fico
  y las pruebas de bondad de ajuste de D'Angostino y Jarque Bera.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{245}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{}Test grÃ¡fico de normalidad}
\PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{resid}\PY{p}{,} \PY{n}{line} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{246}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k+kn}{import} \PY{n}{normaltest}

\PY{c+c1}{\PYZsh{}Test 2 de bondad de ajuste}
\PY{n}{k2}\PY{p}{,} \PY{n}{p\PYZus{}value} \PY{o}{=} \PY{n}{normaltest}\PY{p}{(}\PY{n}{resid}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico = }\PY{l+s+si}{\PYZob{}}\PY{n}{k2}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, p\PYZhy{}value = }\PY{l+s+si}{\PYZob{}}\PY{n}{p\PYZus{}value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico = 3.9803027284582315, p-value = 0.13667473621367196
    \end{Verbatim}

    Al graficar la tendencia de los errores, evidenciamos que este se acerca
mucho a la normalidad. Analizamos el p - valor del test de Jarque - Bera
y de la prueba de D'Angostino, los cuales estÃ¡n por encima del 0.05, lo
que conlleva a aceptar la hipÃ³tesis nula de normalidad de los residuos.

    \hypertarget{modelo-de-regresion-lineal-con-transformaciuxf3n-de-variables}{%
\subsubsection{Modelo de regresion lineal con transformaciÃ³n de
variables}\label{modelo-de-regresion-lineal-con-transformaciuxf3n-de-variables}}

    Para este numeral, se realiza un anÃ¡lisis univariante y bivariante al
conjunto de datos del fichero Data\_Exam1.xlsx. Posteriormente, se
realiza una transformaciÃ³n mediante la funciÃ³n logarÃ­tmica natural de la
Variable ``X'', con base en el comportamiento entre las variables ``X''
y ``Y'', observado mediante un acercamiento grÃ¡fico.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{247}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}lectura del Data set}
\PY{n}{df2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{D:}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{OneDrive \PYZhy{} Tecnoquimicas}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{99. PERSONAL}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{FormaciÃ³n}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Maestria}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Semestre 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Analisis Cuantitivo}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Trabajo 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{data\PYZus{}exam1.xlsx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sheet\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{df2}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{247}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
           Y         X
0  12.189142  0.226957
1  12.187456  0.088938
2  11.782692  0.199069
3   5.732032  0.003812
4   7.026970  0.004573
\end{Verbatim}
\end{tcolorbox}
        
    En un primer acercamiento univariante a los datos mediante la funciÃ³n
``describe'' de Pandas, y complementÃ¡ndolo con una revisiÃ³n grÃ¡fica por
medio de diagramas de cajas para el comportamiento de los datos de las
variables ``X'' y ``Y'', se resaltan los siguientes puntos:

\emph{Variable X} Los valores de la variable X, presentan un valor medio
de 0.07234, con una desviaciÃ³n estÃ¡ndar de 0.09753.

\emph{El primer cuartil (25\%) es aproximadamente 0.0085. }La mediana de
X (50\%) es aproximadamente 0.0366. \emph{El tercer cuartil (75\%) de
los valores de X es aproximadamente 0.0999. }El valor mÃ¡ximo de ``X'' es
aproximadamente 0.9397, lo que sugiere que hay valores muy grandes
presentes en los datos.

Mediante los datos anteriores y complementando con la informaciÃ³n
grÃ¡fica presentada en los sigientes grÃ¡ficos, se resalta para los
valores de X que: presentan una distribuciÃ³n sesgada hacia la derecha,
que la media (0.07234) es significativamente mayor que la mediana
(0.0366) y que hay presencia de valores atÃ­picos considerablemente
superiores en el Ãºltimo cuartil.

\emph{Variable Y} Los valores de la variable ``Y'', presentan un valor
medio de 9.4456, con una desviaciÃ³n estÃ¡ndar de 3.90818.

El 25\% de los datos de Y estÃ¡n por debajo de aproximadamente 7.41, el
50\% de los datos de Y estÃ¡n por debajo de aproximadamente 10.07, y el
75\% de los datos de ``Y'' estÃ¡n por debajo de aproximadamente 12.08.

Mediante los datos anteriores y complementando con la informaciÃ³n
grÃ¡fica presentada en los sigientes grÃ¡ficos, se resalta para los
valores de Y que: presentan una distribuciÃ³n sesgada hacia la izquierda,
se encuentran valores atÃ­picos significativamente menores en el primer
cuartil.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{248}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df2}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{248}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                 Y             X
count  1000.000000  1.000000e+03
mean      9.445622  7.234805e-02
std       3.908189  9.753985e-02
min     -12.073239  1.343729e-08
25\%       7.411486  8.450417e-03
50\%      10.072134  3.655172e-02
75\%      12.082546  9.992523e-02
max      17.838788  9.397465e-01
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{249}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}OrdenaciÃ³n de los grÃ¡ficos espacialmente en una matriz}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{sn}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df2}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Boxplot de la variable X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
\PY{n}{sn}\PY{o}{.}\PY{n}{histplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df2}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de la variable Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Seteo del estilo de los grÃ¡ficos}
\PY{n}{sn}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkgrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_44_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{250}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}OrdenaciÃ³n de los grÃ¡ficos espacialmente en una matriz}
\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{sn}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df2}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Boxplot de la variable X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
\PY{n}{sn}\PY{o}{.}\PY{n}{histplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df2}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de la variable Ind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Seteo del estilo de los grÃ¡ficos}
\PY{n}{sn}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkgrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_45_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Continuamos con el anÃ¡lisis bivariante:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{251}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sn}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{df2}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_47_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{252}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de pearson}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== Pearson =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df2}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pearson}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== spearman =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de spearman}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df2}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{spearman}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== kendall =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de kendall}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df2}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kendall}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
============== Pearson =============
          Y         X
Y  1.000000  0.520376
X  0.520376  1.000000
============== spearman =============
          Y         X
Y  1.000000  0.767833
X  0.767833  1.000000
============== kendall =============
          Y         X
Y  1.000000  0.580777
X  0.580777  1.000000
    \end{Verbatim}

    Se calculan las matrices de correlaciÃ³n, buscando informaciÃ³n sobre la
relaciÃ³n entre las variables X y Y.

*\textbf{CorrelaciÃ³n de Pearson}: Se obtiene una correlaciÃ³n de 0.52,
sugiriendo una relaciÃ³n moderada positiva entre ``X'' y ``Y''.

*\textbf{CorrelaciÃ³n de Spearman}: Se obtiene una correlaciÃ³n 0.77,
sugiriendo una correlaciÃ³n fuerte y positiva entre ``X'' y ``Y''.

*\textbf{CorrelaciÃ³n de Kendall}: Se obtiene una correlaciÃ³n 0.58,
sugiriendo una correlaciÃ³n moderada y positiva entre ``X'' y ``Y''.

Los resultados indican una correlaciÃ³n positiva entre las variables Y y
X. La fuerza de esta correlaciÃ³n varÃ­a ligeramente segÃºn el mÃ©todo
utilizado, pero en general, sugiere que existe una relaciÃ³n positiva
entre las dos variables

Continuamos con la transformaciÃ³n de la variable independiente para la
corrida del modelo.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{253}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Aplicar la transformaciÃ³n logarÃ­tmica a la variable X}
\PY{n}{df2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{df2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{254}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{X} \PY{o}{=} \PY{n}{df2}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}  \PY{c+c1}{\PYZsh{} Variable explicativa}
\PY{n}{y} \PY{o}{=} \PY{n}{df2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}        \PY{c+c1}{\PYZsh{} Variable objetivo}

\PY{c+c1}{\PYZsh{} Agregar intercepto al conjunto de datos}
\PY{n}{X} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir los resultados del modelo}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:                      Y   R-squared:                       0.732
Model:                            OLS   Adj. R-squared:                  0.732
Method:                 Least Squares   F-statistic:                     2726.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):          1.29e-287
Time:                        19:33:20   Log-Likelihood:                -2123.1
No. Observations:                1000   AIC:                             4250.
Df Residuals:                     998   BIC:                             4260.
Df Model:                           1
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         15.1706      0.127    119.481      0.000      14.921      15.420
X\_log          1.4987      0.029     52.209      0.000       1.442       1.555
==============================================================================
Omnibus:                        0.330   Durbin-Watson:                   1.982
Prob(Omnibus):                  0.848   Jarque-Bera (JB):                0.305
Skew:                           0.043   Prob(JB):                        0.858
Kurtosis:                       3.005   Cond. No.                         9.11
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    Se aplica una transformaciÃ³n logarÃ­tmica a la variable `X' utilizando la
funciÃ³n logarÃ­tmica natural. Posterior a esta transformaciÃ³n, se procede
a ajustar un modelo de regresiÃ³n lineal mediante el mÃ©todo de mÃ­nimos
cuadrados ordinarios (OLS), utilizando la variable transformada `X\_log'
como variable explicativa y la variable `Y' como variable objetivo.

De los valores obtenidos, se obtiene que la siguiente, es la funciÃ³n
estimada que describe la relaciÃ³n entre la variable de respuesta Y y la
variable explicativa X, segÃºn el modelo de regresiÃ³n lineal ajustado.

\(\hat{Y} =Î²â +Î²â âXlogâ\)

Donde:

\(\hat{Y}\) es la variable de respuesta (Y) estimada.

Î²â es el coeficiente de intersecciÃ³n (constante).

Î²â es el coeficiente asociado con la variable explicativa X\_log

Encontrando que la siguiente es la funciÃ³n estimada de Y en funciÃ³n de X

\[ \hat{Y}=15.1706+1.4987âln(X) \]

    Una vez corrido el modelo, intepretamos los estadÃ­sticos que nos arroja:

\textbf{Coeficiente (coef)}: El coeficiente para la variable X\_log es
1.4987. Esto sugiere que, en promedio, un aumento unitario en X\_log
estÃ¡ asociado con un aumento de aproximadamente 1.4987 unidades en Y.

\textbf{Valores p (P\textgreater\textbar t\textbar)}: El valor p
obtenido en el modelo, para el coeficiente de X\_log es 0.000, lo que
sugiere que el efecto de X\_log en Y es estadÃ­sticamente significativo.

\textbf{R-cuadrado}: El modelo arroja un valor de R-cuadrado de 0.732,
indicando que aproximadamente el 73.2\% de la variabilidad en la
variable de respuesta (Y) es explicada por la variable explicativa
(X\_log).

\textbf{F-statistic} y \textbf{valor p asociado} : Se obtiene un valor p
asociado significativamente bajo (1.29e-287), indicando que el modelo es
estadÃ­sticamente significativo.

    \hypertarget{validaciuxf3n-de-los-supuestos-del-modelo}{%
\paragraph{ValidaciÃ³n de los supuestos del
modelo}\label{validaciuxf3n-de-los-supuestos-del-modelo}}

A continuaciÃ³n, se presenta la evaluaciÃ³n de los supuestos del modelo,
encontrando que no hay evidencia para rechazar ningun de los supuestos
frente a los residuales.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{255}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{residuals} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{resid}
\end{Verbatim}
\end{tcolorbox}

    Supuesto 1 y supuesto 3 y 4: Los residuales son independientes, Promedio
de los ğáµ¢= 0 y presentan varianza constante

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{256}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{residuals}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GrÃ¡fico de DispersiÃ³n de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicciones}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_57_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    De acuerdo con el grÃ¡fico anterior, se encuentra que los residuos, no
muestran un comportamiento constante al rededor del cero,
especificamente, para valores mayores en el eje X, se observan mayor
valores de residuo, pareciera que los residuos estÃ¡n indicando
heterocedasticidad, es decir, que la varianza de los errores no es
constante a lo largo del rango de predicciones.

A continuaciÃ³n se proceder a evaluar mediante tests de Breusch-Pagan y
Durbin-Watson, si el comportamiento de los residuos presentan o no,
heterocedasticidad y autocorrelaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{257}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{diagnostic} \PY{k+kn}{import} \PY{n}{het\PYZus{}breuschpagan}

\PY{c+c1}{\PYZsh{} Calcula el test de Breusch\PYZhy{}Pagan}
\PY{n}{lm}\PY{p}{,} \PY{n}{lm\PYZus{}p\PYZus{}value}\PY{p}{,} \PY{n}{fvalue}\PY{p}{,} \PY{n}{f\PYZus{}p\PYZus{}value} \PY{o}{=} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{(}\PY{n}{residuals}\PY{p}{,} \PY{n}{X}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprime los resultados}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM EstadÃ­stico:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{lm}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor LM:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{lm\PYZus{}p\PYZus{}value}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{F EstadÃ­stico:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fvalue}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor F:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{f\PYZus{}p\PYZus{}value}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
LM EstadÃ­stico: 0.5282662931659354
P-valor LM: 0.46733665913366673
F EstadÃ­stico: 0.5274884149292246
P-valor F: 0.46783499688166175
    \end{Verbatim}

    Los resultados del test de Breusch-Pagan muestran que el estadÃ­stico LM
es 0.528 y el valor p asociado es 0.467 para el estadÃ­stico LM. AdemÃ¡s,
el estadÃ­stico F es 0.527 con un valor p asociado de 0.468.

Dado que los valores p para ambos estadÃ­sticos, son mayores que 0.05, no
hay suficiente evidencia para rechazar la hipÃ³tesis nula de
homocedasticidad en los residuos. Los residuos parecen tener una
varianza constante, lo que sugiere que no hay heterocedasticidad en el
modelo.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{258}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{stattools} \PY{k+kn}{import} \PY{n}{durbin\PYZus{}watson}

\PY{n}{residuos} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{resid}

\PY{c+c1}{\PYZsh{} Calcular el estadÃ­stico de Durbin\PYZhy{}Watson}
\PY{n}{statistic} \PY{o}{=} \PY{n}{durbin\PYZus{}watson}\PY{p}{(}\PY{n}{residuos}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Durbin\PYZhy{}Watson:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{statistic}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Durbin-Watson: 1.9819250655292384
    \end{Verbatim}

    Dado que el valor obtenido para el estadÃ­stico de Durbin-Watson es
aproximadamente 1.98, estÃ¡ cerca de 2, pareciera que no hay
autocorrelaciÃ³n de primer orden en los residuos. En consecuencia, los
residuos parecen ser independientes entre sÃ­.

Supuesto 2: Los ğáµ¢ presentan una distribuciÃ³n Normal

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{259}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{residuals}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Frecuencia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_63_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{260}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test de Shapiro\PYZhy{}Wilk para validaciÃ³n de Normalidad en los residuales}

\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k+kn}{import} \PY{n}{stats}

\PY{n}{shapiro\PYZus{}result} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{shapiro}\PY{p}{(}\PY{n}{residuals}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado del test}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Shapiro\PYZhy{}Wilk:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Interpretar el resultado del test}
\PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}
\PY{k}{if} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue} \PY{o}{\PYZgt{}} \PY{n}{alpha}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{No se puede rechazar la hipÃ³tesis nula. Los residuos siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{else}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Shapiro-Wilk: 0.9991617550230457
P-valor: 0.9427671920709753
No se puede rechazar la hipÃ³tesis nula. Los residuos siguen una distribuciÃ³n
normal.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{261}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}import statsmodels.api as sm}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{gofplots} \PY{k}{as} \PY{n+nn}{smg}

\PY{c+c1}{\PYZsh{}  grÃ¡fico QQPlot}
\PY{n}{fig} \PY{o}{=} \PY{n}{smg}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{residuals}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Mostrar el grÃ¡fico}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_65_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Considerando el acercamiento grÃ¡fico de los residuales del modelo,
mediante el histograma de los residuales y el diagrama QQPlot, se pueden
apreciar comportamientos de los residuales que se aproximan a una
distribuciÃ³n Normal. se realizÃ³ el test de Shapiro-Wilk, obteniendo un
valor p de 0.943. Dado que este valor p es superior al nivel de
significancia establecido, no se puede rechazar la hipÃ³tesis nula de
normalidad. Por lo tanto, se concluye que los residuos se distribuyen de
manera normal

    \hypertarget{ejercicio-de-regresiuxf3n-lineal-con-cuxe1lculo-matricial}{%
\subsubsection{Ejercicio de regresiÃ³n lineal con cÃ¡lculo
matricial}\label{ejercicio-de-regresiuxf3n-lineal-con-cuxe1lculo-matricial}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{262}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Se excluyen dos filas ya que la primera fila se trata del tÃ­tulo, y segunda fila es un espacio en blanco}
\PY{n}{df3} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{D:}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{OneDrive \PYZhy{} Tecnoquimicas}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{99. PERSONAL}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{FormaciÃ³n}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Maestria}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Semestre 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Analisis Cuantitivo}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Trabajo 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{datos.xls}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{sheet\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Wine Quality}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{skiprows}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
\PY{n}{df3}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{262}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Calidad del Vino  Acidez Fija  Acidez VolÃ¡til  Ãcido CÃ­trico  \textbackslash{}
0                 6          7.0            0.27           0.36
1                 6          6.3            0.30           0.34
2                 6          8.1            0.28           0.40
3                 6          7.2            0.23           0.32
4                 6          7.2            0.23           0.32

   AzÃºcar Residual  Cloruros  DiÃ³xido de AzÃºfre Libre  \textbackslash{}
0             20.7     0.045                     45.0
1              1.6     0.049                     14.0
2              6.9     0.050                     30.0
3              8.5     0.058                     47.0
4              8.5     0.058                     47.0

   DiÃ³xido de AzÃºfre Total  Densidad    pH  Sulfatos  Alcohol
0                    170.0    1.0010  3.00      0.45      8.8
1                    132.0    0.9940  3.30      0.49      9.5
2                     97.0    0.9951  3.26      0.44     10.1
3                    186.0    0.9956  3.19      0.40      9.9
4                    186.0    0.9956  3.19      0.40      9.9
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{263}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df3}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 4898 entries, 0 to 4897
Data columns (total 12 columns):
 \#   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   Calidad del Vino         4898 non-null   int64
 1   Acidez Fija              4898 non-null   float64
 2   Acidez VolÃ¡til           4898 non-null   float64
 3   Ãcido CÃ­trico            4898 non-null   float64
 4   AzÃºcar Residual          4898 non-null   float64
 5   Cloruros                 4898 non-null   float64
 6   DiÃ³xido de AzÃºfre Libre  4898 non-null   float64
 7   DiÃ³xido de AzÃºfre Total  4898 non-null   float64
 8   Densidad                 4898 non-null   float64
 9   pH                       4898 non-null   float64
 10  Sulfatos                 4898 non-null   float64
 11  Alcohol                  4898 non-null   float64
dtypes: float64(11), int64(1)
memory usage: 459.3 KB
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{264}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{columnas\PYZus{}a\PYZus{}excluir} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Sulfatos}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cloruros}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Acidez VolÃ¡til}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Acidez Fija}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Calidad del Vino}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Crear un nuevo DataFrame excluyendo las columnas especificadas}
\PY{n}{df3} \PY{o}{=} \PY{n}{df3}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{n}{columnas\PYZus{}a\PYZus{}excluir}\PY{p}{)}

\PY{n}{columnas\PYZus{}ordenadas} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{+} \PY{p}{[}\PY{n}{col} \PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{df3}\PY{o}{.}\PY{n}{columns} \PY{k}{if} \PY{n}{col} \PY{o}{!=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{df3} \PY{o}{=} \PY{n}{df3}\PY{p}{[}\PY{n}{columnas\PYZus{}ordenadas}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{265}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sn}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{df3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{265}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<seaborn.axisgrid.PairGrid at 0x14d921ea910>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_71_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{266}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df3}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{df3}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{267}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{267}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([[0.99272],
       [0.9968 ],
       [0.99268],
       {\ldots},
       [0.99129],
       [0.99567],
       [0.99255]])
\end{Verbatim}
\end{tcolorbox}
        
    Estandarizamos las variables, lo que nos garantiza que la matriz de
covarianza se calcularÃ¡ estandarizada, es decir, calcularemos los
indices de correlaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{268}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}EstandarizaciÃ³n de las variables}
\PY{n}{scalerX} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Esta linea instancia la clase que va a calcular la estandarizaciÃ³n}
\PY{n}{scalerX}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Ajustamos el scaler a nuestros datos df}
\PY{n}{datosX\PYZus{}scaled} \PY{o}{=} \PY{n}{scalerX}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} AsÃ­ calculo la estandarizaciÃ³n de los datos}
\PY{n}{dfX\PYZus{}scaled} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{datosX\PYZus{}scaled}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{)}
\PY{n}{dfX\PYZus{}scaled}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{268}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Ãcido CÃ­trico  AzÃºcar Residual  DiÃ³xido de AzÃºfre Libre  \textbackslash{}
0       0.227731         0.340419                 0.534065
1       0.895832         1.002071                 0.773947
2      -0.022807         0.184737                -0.605377
3       0.144218        -0.924503                -0.125612
4      -0.607396         2.432407                 0.054300

   DiÃ³xido de AzÃºfre Total   Alcohol
0                -0.641932  1.540371
1                 1.355106 -0.821712
2                -1.022320  0.481506
3                -0.879675  0.237153
4                 0.855846 -0.088652
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{269}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{scalerY} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
\PY{n}{scalerY}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{datosY\PYZus{}scaled} \PY{o}{=} \PY{n}{scalerY}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} AsÃ­ calculo la estandarizaciÃ³n de los datos}
\PY{n}{datosY\PYZus{}scaled}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{269}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([[-0.44704073],
       [ 0.90336975],
       [-0.46028004],
       {\ldots},
       [-0.92034636],
       [ 0.52935901],
       [-0.50330783]])
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{270}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Mediante la matriz de covarianzas, se valida que los datos estÃ¡n estandazarizdos, se obtienen 1 en la diagonal}
\PY{n}{dfX\PYZus{}scaled}\PY{o}{.}\PY{n}{cov}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{270}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                         Ãcido CÃ­trico  AzÃºcar Residual  \textbackslash{}
Ãcido CÃ­trico                 1.000255         0.092536
AzÃºcar Residual               0.092536         1.000255
DiÃ³xido de AzÃºfre Libre       0.098112         0.306096
DiÃ³xido de AzÃºfre Total       0.122396         0.406054
Alcohol                      -0.062996        -0.453598

                         DiÃ³xido de AzÃºfre Libre  DiÃ³xido de AzÃºfre Total  \textbackslash{}
Ãcido CÃ­trico                           0.098112                 0.122396
AzÃºcar Residual                         0.306096                 0.406054
DiÃ³xido de AzÃºfre Libre                 1.000255                 0.614348
DiÃ³xido de AzÃºfre Total                 0.614348                 1.000255
Alcohol                                -0.257323                -0.454558

                          Alcohol
Ãcido CÃ­trico           -0.062996
AzÃºcar Residual         -0.453598
DiÃ³xido de AzÃºfre Libre -0.257323
DiÃ³xido de AzÃºfre Total -0.454558
Alcohol                  1.000255
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{271}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{datosY\PYZus{}scaled}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{271}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
array([[-0.44704073,  0.90336975, -0.46028004, {\ldots}, -0.92034636,
         0.52935901, -0.50330783]])
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{272}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Se ubica a la variable Densidad como primer Variable de izquierda a derecha dentro del conjunto del dataset}
\PY{n}{df\PYZus{}scaled} \PY{o}{=} \PY{n}{dfX\PYZus{}scaled}
\PY{n}{df\PYZus{}scaled}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{datosY\PYZus{}scaled}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

\PY{n}{df\PYZus{}scaled} \PY{o}{=} \PY{n}{df\PYZus{}scaled}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ãcido CÃ­trico}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AzÃºcar Residual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xido de AzÃºfre Libre}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xido de AzÃºfre Total}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Alcohol}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Cambiar los nombres de las columnas}
\PY{n}{df\PYZus{}scaled} \PY{o}{=} \PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{rename}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xido de AzÃºfre Libre}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xidoAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ãcido CÃ­trico}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ÃcidoC}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AzÃºcar Residual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AzÃºcarR}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xido de AzÃºfre Total}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xidoZT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Reordenar las columnas}
\PY{n}{df\PYZus{}scaled} \PY{o}{=} \PY{n}{df\PYZus{}scaled}\PY{p}{[}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ÃcidoC}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AzÃºcarR}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xidoAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DiÃ³xidoZT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Alcohol}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}

\PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{272}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Densidad    ÃcidoC   AzÃºcarR  DiÃ³xidoAL  DiÃ³xidoZT   Alcohol
0 -0.447041  0.227731  0.340419   0.534065  -0.641932  1.540371
1  0.903370  0.895832  1.002071   0.773947   1.355106 -0.821712
2 -0.460280 -0.022807  0.184737  -0.605377  -1.022320  0.481506
3 -0.304718  0.144218 -0.924503  -0.125612  -0.879675  0.237153
4  1.883079 -0.607396  2.432407   0.054300   0.855846 -0.088652
\end{Verbatim}
\end{tcolorbox}
        
    Una vez tenemos las variables estandarizadas, procedemos a hacer el
cÃ¡lculo de coeficientes a travÃ©s de la soluciÃ³n matricial.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{273}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de pearson}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== Pearson =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pearson}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Redondear a 2 cifras decimales}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== spearman =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de spearman}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{spearman}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Redondear a 2 cifras decimales}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{============== kendall =============}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} calculando la correlaciÃ³n de kendall}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kendall}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Redondear a 2 cifras decimales}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
============== Pearson =============
           Densidad  ÃcidoC  AzÃºcarR  DiÃ³xidoAL  DiÃ³xidoZT  Alcohol
Densidad      1.000   0.143    0.843      0.300      0.532   -0.775
ÃcidoC        0.143   1.000    0.093      0.098      0.122   -0.063
AzÃºcarR       0.843   0.093    1.000      0.306      0.406   -0.453
DiÃ³xidoAL     0.300   0.098    0.306      1.000      0.614   -0.257
DiÃ³xidoZT     0.532   0.122    0.406      0.614      1.000   -0.454
Alcohol      -0.775  -0.063   -0.453     -0.257     -0.454    1.000
============== spearman =============
           Densidad  ÃcidoC  AzÃºcarR  DiÃ³xidoAL  DiÃ³xidoZT  Alcohol
Densidad      1.000   0.088    0.781      0.329      0.565   -0.823
ÃcidoC        0.088   1.000    0.026      0.092      0.094   -0.021
AzÃºcarR       0.781   0.026    1.000      0.345      0.429   -0.449
DiÃ³xidoAL     0.329   0.092    0.345      1.000      0.622   -0.275
DiÃ³xidoZT     0.565   0.094    0.429      0.622      1.000   -0.479
Alcohol      -0.823  -0.021   -0.449     -0.275     -0.479    1.000
============== kendall =============
           Densidad  ÃcidoC  AzÃºcarR  DiÃ³xidoAL  DiÃ³xidoZT  Alcohol
Densidad      1.000   0.059    0.590      0.218      0.389   -0.636
ÃcidoC        0.059   1.000    0.016      0.063      0.063   -0.014
AzÃºcarR       0.590   0.016    1.000      0.236      0.292   -0.308
DiÃ³xidoAL     0.218   0.063    0.236      1.000      0.448   -0.184
DiÃ³xidoZT     0.389   0.063    0.292      0.448      1.000   -0.327
Alcohol      -0.636  -0.014   -0.308     -0.184     -0.327    1.000
    \end{Verbatim}

    Considerando los valores obtenidos en las matrices de correlaciÃ³n, se
resaltan las siguientes observaciones sobre las estructuras de
dependencia entre las variables:

\textbf{\emph{En la matriz de correlaciÃ³n de Pearson:}} *La densidad
parece estar altamente correlacionada con el azÃºcar residual (0.843) y
moderadamente correlacionada con el diÃ³xido de azufre libre (0.300) y el
diÃ³xido de azufre total (0.532). AdemÃ¡s, muestra una correlaciÃ³n
negativa fuerte con el alcohol (-0.775).

*El alcohol parece estar negativamente correlacionado con la densidad
(-0.775). Las otras correlaciones son relativamente bajas.

\textbf{\emph{En la matriz de correlaciÃ³n de Spearman:}} Se observan
patrones similares a la matriz de correlaciÃ³n de Pearson, pero las
correlaciones tienden a ser ligeramente menores.

La densidad aÃºn muestra una alta correlaciÃ³n con el azÃºcar residual
(0.781) y correlaciones negativas fuertes con el alcohol (-0.823).

\textbf{\emph{En la matriz de correlaciÃ³n de Kendall:}} Los patrones
generales son similares a las matrices anteriores, pero las
correlaciones tienden a ser mÃ¡s bajas.

En resumen, las estructuras de dependencia observadas en la

    \hypertarget{modelo-de-regresiuxf3n-lineal}{%
\paragraph{Modelo de regresiÃ³n
lineal}\label{modelo-de-regresiuxf3n-lineal}}

Dado que los datos del modelo de regresiÃ³n se encuentran estandarizado,
se procede a calcular los coeficientes regresiÃ³n directamente con la
matrix de correlaciones \(C\) de la sigueinte forma

\[\beta_{1\ldots p}=C_{XX}^{-1}C_Xy \hspace{1 cm} \beta_0=0\]

Partiendo de los datos estandarizados, y tomando como variable respuesta
Columna Densidad, se han construÃ­do 3 modelos RLM partiendo de las
matrices de correlaciÃ³n calculadas mediante los mÃ©todos Pearson, Kendall
y Spearman.

Para los 3 modelos se calcula el RMSE de la predicciÃ³n, obteniendo los
siguientes valores para cada modelo, encontrado que el Modelo calculado
a partir de la matriz de correlaciÃ³n de kendall, reduce las desviaciones
de las predicciÃ³n del modelo, respecto a los valores reales, comparados
con los otros dos modelos RLM calculados.

RMSE (Pearson)= 1.3863748432263951 RMSE (Kendall)= 1.2968506359111867
RMSE (Spearman)= 1.3875694897018205

Ninguno de los tres modelos de RLM calculados, cumplen los supuestos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{274}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}A continuaciÃ³n se calculan los coeficientes de regresiÃ³n mediante la expresiÃ³n anterior de matriz de correlaciÃ³n}

\PY{c+c1}{\PYZsh{}Definimos una funciÃ³n que permita hacer el cÃ¡lculo de los coeficientes mediante diferentes mÃ©todos}

\PY{k}{def} \PY{n+nf}{RLC}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{p}{,} \PY{n}{method\PYZus{}name}\PY{p}{)}\PY{p}{:}

  \PY{n}{C} \PY{o}{=} \PY{n}{df\PYZus{}scaled}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{method\PYZus{}name}\PY{p}{)}

  \PY{n}{CXX} \PY{o}{=} \PY{n}{C}\PY{o}{.}\PY{n}{to\PYZus{}numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]} \PY{c+c1}{\PYZsh{}DefiniciÃ³n de la matriz CXX No considera la primera columna ni la primera fila, la cual hace referencia a la variable \PYZdq{}Densidad\PYZdq{} que es la variable respuesta}

  \PY{n}{CXy} \PY{o}{=} \PY{n}{C}\PY{o}{.}\PY{n}{to\PYZus{}numpy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]} \PY{c+c1}{\PYZsh{}DefiniciÃ³n del Vecto CXY Vector de correlaciÃ³n de las variables de entrada respecto a la variable respuesta}

  \PY{n}{betas} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{inv}\PY{p}{(}\PY{n}{CXX}\PY{p}{)}\PY{p}{,} \PY{n}{CXy}\PY{p}{)} \PY{c+c1}{\PYZsh{}CÃ¡lculo de los Betas}

  \PY{k}{return} \PY{n}{betas}
\end{Verbatim}
\end{tcolorbox}

    Calculamos los coeficientes del modelo usando Spearman

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{275}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}A continuaciÃ³n se calculan los coeficientes de regresiÃ³n mediante la expresiÃ³n anterior de matriz de correlaciÃ³n}
\PY{c+c1}{\PYZsh{}MÃ©todo Spearman}
\PY{c+c1}{\PYZsh{}B0=0 considerando que los datos estÃ¡n estandarizados}

\PY{n}{betas} \PY{o}{=} \PY{n}{RLC}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{spearman}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{betas}
\PY{c+c1}{\PYZsh{}Los valores de Beta mayores, representan mayor dependencia a la variable}

\PY{c+c1}{\PYZsh{} Imprimir el mensaje en pantalla}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman, }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y= }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)} \PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de
regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman,
y= Î²â0.058673439357240245 + Î²â0.5025917375311488 + Î²â-0.08268649813250786 +
Î²â0.12801828839822846 + Î²â-0.557513820380729
    \end{Verbatim}

    Siendo Î²â asociado a los valores obtenidos por la variable Ãcido CÃ­trico
Î²â asociado a los valores obtenidos por la variable AzÃºcar Residual Î²â
asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre Libre
Î²â asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre
Total Î²â asociado a los valores obtenidos por la variable Alcohol

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{276}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}test\PYZus{}scaled} \PY{o}{=} \PY{n}{scalerX}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaled}\PY{p}{,} \PY{n}{betas}\PY{p}{)} \PY{c+c1}{\PYZsh{}}

\PY{n}{residuales} \PY{o}{=} \PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{scalerY}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{277}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}

\PY{c+c1}{\PYZsh{} Calcular el RMSE}
\PY{n}{rmse} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{En promedio, las predicciones del modelo tienen un error de aproximadamente:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rmse}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
En promedio, las predicciones del modelo tienen un error de aproximadamente:
1.3875694897018205
    \end{Verbatim}

    Considerando que las variables del modelo, estÃ¡n estandarizadas, el RMSE
obtenido, indica que en promedio, las predicciones del modelo mediante
el mÃ©todo Spearman, estÃ¡n desviadas de los valores reales en alrededor
de 1.3876 desviaciones estÃ¡ndar de la variable objetivo (Densidad).

    \hypertarget{validaciuxf3n-de-supuestos-spearman}{%
\paragraph{ValidaciÃ³n de supuestos
(Spearman)}\label{validaciuxf3n-de-supuestos-spearman}}

Mediante la evaluaciÃ³n de los supuestos del modelo, presentada a
continuaciÃ³n, se encuentra que hay evidencia significativa para rechazar
la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se concluye que hay
heterocedasticidad en los residuos del modelo, adicionalmente, se
rechaza la hipÃ³tesis nula en el test Shapiro-Wilk; Los residuos no
siguen una distribuciÃ³n normal.

En resumen, dado que se encuentra evidencia de heterocedasticidad y no
se cumple el supuesto de normalidad de los residuos, no es correcto el
uso del modelo y tendrÃ­a que revisarse tÃ©cnicas de modelado alternativas
o ajustes en el modelo para abordar estas deficiencias y mejorar la
precisiÃ³n de las estimaciones.

Supuesto 1 y supuesto 3 y 4: Los residuales son independientes, Promedio
de los ğáµ¢= 0 y presentan varianza constante

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{278}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{residuales}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GrÃ¡fico de DispersiÃ³n de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicciones}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agregar lÃ­nea horizontal en y=0}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_92_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    De acuerdo con el grÃ¡fico anterior, se encuentra que los residuos,
parecieran mostrar un comportamiento constante al rededor de cero, sin
embargo pareciera mostrar una leve concentraciÃ³n en valores superiores a
cero.

A continuaciÃ³n se proceder a evaluar mediante tests de Breusch-Pagan y
Durbin-Watson, si el comportamiento de los residuos presentan o no,
heterocedasticidad y autocorrelaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{279}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajusta un modelo auxiliar para explicar la varianza de los residuos}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{X\PYZus{}test}  \PY{c+c1}{\PYZsh{} Puedes utilizar las variables originales o alguna transformaciÃ³n de estas}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}auxiliar}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agrega una constante si es necesario}
\PY{n}{model\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}auxiliar}\PY{p}{)}
\PY{n}{results\PYZus{}auxiliar} \PY{o}{=} \PY{n}{model\PYZus{}auxiliar}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calcula el estadÃ­stico LM para el test de Breusch\PYZhy{}Pagan}
\PY{n}{BP\PYZus{}statistic} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{rsquared}
\PY{c+c1}{\PYZsh{} Calcula el p\PYZhy{}valor asociado al estadÃ­stico LM}
\PY{n}{p\PYZus{}valor\PYZus{}BP} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{f\PYZus{}pvalue}

\PY{c+c1}{\PYZsh{} Imprime los resultados}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{BP\PYZus{}statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor del test de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{p\PYZus{}valor\PYZus{}BP}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Breusch-Pagan: 0.07871791973180509
P-valor del test de Breusch-Pagan: 8.475640489544816e-16
    \end{Verbatim}

    Teniendo en cuenta los resultados del test de Breusch-Pagan, dado un
valor p significativamente bajo, hay evidencia significativa para
rechazar la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se
concluye que hay heterocedasticidad en los residuos del modelo.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{280}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{stattools} \PY{k+kn}{import} \PY{n}{durbin\PYZus{}watson}

\PY{n}{residuos} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{resid}

\PY{c+c1}{\PYZsh{} Calcular el estadÃ­stico de Durbin\PYZhy{}Watson}
\PY{n}{statistic} \PY{o}{=} \PY{n}{durbin\PYZus{}watson}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Durbin\PYZhy{}Watson:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{statistic}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Durbin-Watson: 2.0374809484643865
    \end{Verbatim}

    Dado que el valor obtenido para el estadÃ­stico de Durbin-Watson es
aproximadamente 2.0375, estÃ¡ cerca de 2, pareciera que no hay
autocorrelaciÃ³n de primer orden en los residuos. En consecuencia, los
residuos parecen ser independientes entre sÃ­.

Supuesto 2: Los ğáµ¢ presentan una distribuciÃ³n Normal

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{281}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Frecuencia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_98_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{282}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}import statsmodels.api as sm}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{gofplots} \PY{k}{as} \PY{n+nn}{smg}

\PY{c+c1}{\PYZsh{}  grÃ¡fico QQPlot}
\PY{n}{fig} \PY{o}{=} \PY{n}{smg}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Mostrar el grÃ¡fico}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_99_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{283}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test de Shapiro\PYZhy{}Wilk para validaciÃ³n de Normalidad en los residuales}

\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k+kn}{import} \PY{n}{stats}

\PY{n}{shapiro\PYZus{}result} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{shapiro}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado del test}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Shapiro\PYZhy{}Wilk:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Interpretar el resultado del test}
\PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}
\PY{k}{if} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue} \PY{o}{\PYZgt{}} \PY{n}{alpha}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{No se puede rechazar la hipÃ³tesis nula. Los residuos siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{else}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Shapiro-Wilk: 0.9878932480248609
P-valor: 3.1071658287470245e-07
Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.
    \end{Verbatim}

    CÃ¡lculo del modelo de regresion usando Kendall:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{284}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}A continuaciÃ³n se calculan los coeficientes de regresiÃ³n mediante la expresiÃ³n anterior de matriz de correlaciÃ³n}
\PY{c+c1}{\PYZsh{}MÃ©todo Kendall}
\PY{c+c1}{\PYZsh{}B0=0 considerando que los datos estÃ¡n estandarizados}

\PY{n}{betas} \PY{o}{=} \PY{n}{RLC}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kendall}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{betas}
\PY{c+c1}{\PYZsh{}Los valores de Beta mayores, representan mayor dependencia a la variable}

\PY{c+c1}{\PYZsh{} Imprimir el mensaje en pantalla}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman, }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y= }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)} \PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de
regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman,
y= Î²â0.03929951889239226 + Î²â0.4138869957611103 + Î²â-0.02379283098767225 +
Î²â0.12203927691759384 + Î²â-0.4720047863901405
    \end{Verbatim}

    Siendo Î²â asociado a los valores obtenidos por la variable Ãcido CÃ­trico
Î²â asociado a los valores obtenidos por la variable AzÃºcar Residual Î²â
asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre Libre
Î²â asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre
Total Î²â asociado a los valores obtenidos por la variable Alcohol

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{285}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}test\PYZus{}scaled} \PY{o}{=} \PY{n}{scalerX}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaled}\PY{p}{,} \PY{n}{betas}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{286}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Calculo de RMSE Root Mean Squared Error}

\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}

\PY{n}{rmse} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{En promedio, las predicciones del modelo tienen un error de aproximadamente:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rmse}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
En promedio, las predicciones del modelo tienen un error de aproximadamente:
1.2968506359111867
    \end{Verbatim}

    Considerando que las variables del modelo, estÃ¡n estandarizadas, el RMSE
obtenido, indica que en promedio, las predicciones del modelo mediante
el mÃ©todo Kendall, estÃ¡n desviadas de los valores reales en alrededor de
1.2969 desviaciones estÃ¡ndar de la variable objetivo (Densidad).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{287}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{residuales} \PY{o}{=} \PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{scalerY}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{validaciuxf3n-de-los-supuestos-kendall}{%
\paragraph{ValidaciÃ³n de los supuestos
(Kendall)}\label{validaciuxf3n-de-los-supuestos-kendall}}

Mediante la evaluaciÃ³n de los supuestos del modelo, presentada a
continuaciÃ³n, se encuentra que hay evidencia significativa para rechazar
la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se concluye que hay
heterocedasticidad en los residuos del modelo, adicionalmente, se
rechaza la hipÃ³tesis nula en el test Shapiro-Wilk; Los residuos no
siguen una distribuciÃ³n normal.

En resumen, dado que se encuentra evidencia de heterocedasticidad y no
se cumple el supuesto de normalidad de los residuos, no es correcto el
uso del modelo y tendrÃ­a que revisarse tÃ©cnicas de modelado alternativas
o ajustes en el modelo para abordar estas deficiencias y mejorar la
precisiÃ³n de las estimaciones.

Supuesto 1 y supuesto 3 y 4: Los residuales son independientes, Promedio
de los ğáµ¢= 0 y presentan varianza constante

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{288}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{residuales}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agregar lÃ­nea horizontal en y=0}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_109_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    De acuerdo con el grÃ¡fico anterior, se encuentra que los residuos,
parecieran mostrar un comportamiento constante al rededor de cero, sin
embargo pareciera mostrar una leve concentraciÃ³n en valores superiores a
cero.

A continuaciÃ³n se proceder a evaluar mediante tests de Breusch-Pagan y
Durbin-Watson, si el comportamiento de los residuos presentan o no,
heterocedasticidad y autocorrelaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{289}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajusta un modelo auxiliar para explicar la varianza de los residuos}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{X\PYZus{}test}  \PY{c+c1}{\PYZsh{} Puedes utilizar las variables originales o alguna transformaciÃ³n de estas}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}auxiliar}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agrega una constante si es necesario}
\PY{n}{model\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}auxiliar}\PY{p}{)}
\PY{n}{results\PYZus{}auxiliar} \PY{o}{=} \PY{n}{model\PYZus{}auxiliar}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calcula el estadÃ­stico LM para el test de Breusch\PYZhy{}Pagan}
\PY{n}{BP\PYZus{}statistic} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{rsquared}
\PY{c+c1}{\PYZsh{} Calcula el p\PYZhy{}valor asociado al estadÃ­stico LM}
\PY{n}{p\PYZus{}valor\PYZus{}BP} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{f\PYZus{}pvalue}

\PY{c+c1}{\PYZsh{} Imprime los resultados}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{BP\PYZus{}statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor del test de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{p\PYZus{}valor\PYZus{}BP}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Breusch-Pagan: 0.016993546999909848
P-valor del test de Breusch-Pagan: 0.005063412541841041
    \end{Verbatim}

    Teniendo en cuenta los resultados del test de Breusch-Pagan, dado un
valor p significativamente bajo, hay evidencia significativa para
rechazar la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se
concluye que hay heterocedasticidad en los residuos del modelo

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{290}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{stattools} \PY{k+kn}{import} \PY{n}{durbin\PYZus{}watson}

\PY{n}{residuos} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{resid}

\PY{c+c1}{\PYZsh{} Calcular el estadÃ­stico de Durbin\PYZhy{}Watson}
\PY{n}{statistic} \PY{o}{=} \PY{n}{durbin\PYZus{}watson}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Durbin\PYZhy{}Watson:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{statistic}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Durbin-Watson: 2.022273885522051
    \end{Verbatim}

    Supuesto 2: Los ğáµ¢ presentan una distribuciÃ³n Normal

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{291}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Frecuencia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_115_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{292}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}import statsmodels.api as sm}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{gofplots} \PY{k}{as} \PY{n+nn}{smg}

\PY{c+c1}{\PYZsh{}  grÃ¡fico QQPlot}
\PY{n}{fig} \PY{o}{=} \PY{n}{smg}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Mostrar el grÃ¡fico}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_116_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{293}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test de Shapiro\PYZhy{}Wilk para validaciÃ³n de Normalidad en los residuales}

\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k+kn}{import} \PY{n}{stats}

\PY{n}{shapiro\PYZus{}result} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{shapiro}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado del test}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Shapiro\PYZhy{}Wilk:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Interpretar el resultado del test}
\PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}
\PY{k}{if} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue} \PY{o}{\PYZgt{}} \PY{n}{alpha}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{No se puede rechazar la hipÃ³tesis nula. Los residuos siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{else}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Shapiro-Wilk: 0.9823205650104967
P-valor: 1.5967563982052289e-09
Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.
    \end{Verbatim}

    Calculo del modelo usando Pearson:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{294}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}A continuaciÃ³n se calculan los coeficientes de regresiÃ³n mediante la expresiÃ³n anterior de matriz de correlaciÃ³n}
\PY{c+c1}{\PYZsh{}MÃ©todo pearson}
\PY{c+c1}{\PYZsh{}B0=0 considerando que los datos estÃ¡n estandarizados}

\PY{n}{betas} \PY{o}{=} \PY{n}{RLC}\PY{p}{(}\PY{n}{df\PYZus{}scaled}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pearson}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{betas}
\PY{c+c1}{\PYZsh{}Los valores de Beta mayores, representan mayor dependencia a la variable}

\PY{c+c1}{\PYZsh{} Imprimir el mensaje en pantalla}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman, }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y= }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)} \PY{o}{+}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ + }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Î²â}\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{betas}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
La siguiente es la expresiÃ³n del modelo calculado, estimando los coeficientes de
regresiÃ³n mediante la matriz de correlaciÃ³n obtenida usando Spearman,
y= Î²â0.05154898889384292 + Î²â0.6046284708827587 + Î²â-0.08339784307542122 +
Î²â0.12011899954889196 + Î²â-0.46400145920757185
    \end{Verbatim}

    Siendo Î²â asociado a los valores obtenidos por la variable Ãcido CÃ­trico
Î²â asociado a los valores obtenidos por la variable AzÃºcar Residual Î²â
asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre Libre
Î²â asociado a los valores obtenidos por la variable DiÃ³xido de AzÃºfre
Total Î²â asociado a los valores obtenidos por la variable Alcohol

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{295}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}test\PYZus{}scaled} \PY{o}{=} \PY{n}{scalerX}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}

\PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{X\PYZus{}test\PYZus{}scaled}\PY{p}{,} \PY{n}{betas}\PY{p}{)} \PY{c+c1}{\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{296}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Calculo de RMSE Root Mean Squared Error}

\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}

\PY{n}{rmse} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{En promedio, las predicciones del modelo tienen un error de aproximadamente:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{rmse}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
En promedio, las predicciones del modelo tienen un error de aproximadamente:
1.3863748432263951
    \end{Verbatim}

    Considerando que las variables del modelo, estÃ¡n estandarizadas, el RMSE
obtenido, indica que en promedio, las predicciones del modelo mediante
el mÃ©todo Pearson, estÃ¡n desviadas de los valores reales en alrededor de
1.38 desviaciones estÃ¡ndar de la variable objetivo (Densidad).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{297}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{residuales} \PY{o}{=} \PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{scalerY}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{validaciuxf3n-de-los-supuestos-pearson}{%
\paragraph{ValidaciÃ³n de los supuestos
(Pearson)}\label{validaciuxf3n-de-los-supuestos-pearson}}

Mediante la evaluaciÃ³n de los supuestos del modelo, presentada a
continuaciÃ³n, se encuentra que hay evidencia significativa para rechazar
la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se concluye que hay
heterocedasticidad en los residuos del modelo, adicionalmente, se
rechaza la hipÃ³tesis nula en el test Shapiro-Wilk; Los residuos no
siguen una distribuciÃ³n normal.

En resumen, dado que se encuentra evidencia de heterocedasticidad y no
se cumple el supuesto de normalidad de los residuos, no es correcto el
uso del modelo y tendrÃ­a que revisarse tÃ©cnicas de modelado alternativas
o ajustes en el modelo para abordar estas deficiencias y mejorar la
precisiÃ³n de las estimaciones.

Supuesto 1 y supuesto 3 y 4: Los residuales son independientes, Promedio
de los ğáµ¢= 0 y presentan varianza constante

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{298}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{residuales}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agregar lÃ­nea horizontal en y=0}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_126_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    De acuerdo con el grÃ¡fico anterior, se encuentra que los residuos,
parecieran mostrar un comportamiento constante al rededor de cero.

A continuaciÃ³n se proceder a evaluar mediante tests de Breusch-Pagan y
Durbin-Watson, si el comportamiento de los residuos presentan o no,
heterocedasticidad y autocorrelaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{299}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajusta un modelo auxiliar para explicar la varianza de los residuos}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{X\PYZus{}test}  \PY{c+c1}{\PYZsh{} Puedes utilizar las variables originales o alguna transformaciÃ³n de estas}
\PY{n}{X\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X\PYZus{}auxiliar}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Agrega una constante si es necesario}
\PY{n}{model\PYZus{}auxiliar} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}auxiliar}\PY{p}{)}
\PY{n}{results\PYZus{}auxiliar} \PY{o}{=} \PY{n}{model\PYZus{}auxiliar}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calcula el estadÃ­stico LM para el test de Breusch\PYZhy{}Pagan}
\PY{n}{BP\PYZus{}statistic} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{rsquared}
\PY{c+c1}{\PYZsh{} Calcula el p\PYZhy{}valor asociado al estadÃ­stico LM}
\PY{n}{p\PYZus{}valor\PYZus{}BP} \PY{o}{=} \PY{n}{results\PYZus{}auxiliar}\PY{o}{.}\PY{n}{f\PYZus{}pvalue}

\PY{c+c1}{\PYZsh{} Imprime los resultados}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{BP\PYZus{}statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor del test de Breusch\PYZhy{}Pagan:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{p\PYZus{}valor\PYZus{}BP}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Breusch-Pagan: 0.04044358779539037
P-valor del test de Breusch-Pagan: 1.315862938375713e-07
    \end{Verbatim}

    Teniendo en cuenta los resultados del test de Breusch-Pagan, dado un
valor p significativamente bajo, hay evidencia significativa para
rechazar la hipÃ³tesis nula de homocedasticidad. Por lo tanto, se
concluye que hay heterocedasticidad en los residuos del modelo

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{300}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{stattools} \PY{k+kn}{import} \PY{n}{durbin\PYZus{}watson}

\PY{n}{residuos} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{resid}

\PY{c+c1}{\PYZsh{} Calcular el estadÃ­stico de Durbin\PYZhy{}Watson}
\PY{n}{statistic} \PY{o}{=} \PY{n}{durbin\PYZus{}watson}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Durbin\PYZhy{}Watson:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{statistic}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Durbin-Watson: 1.996266746756021
    \end{Verbatim}

    Dado que el valor obtenido para el estadÃ­stico de Durbin-Watson es
aproximadamente 2.0375, estÃ¡ cerca de 2, pareciera que no hay
autocorrelaciÃ³n de primer orden en los residuos. En consecuencia, los
residuos parecen ser independientes entre sÃ­.

Supuesto 2: Los ğáµ¢ presentan una distribuciÃ³n Normal

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{301}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Histograma de Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Residuos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Frecuencia}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_132_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{302}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}import statsmodels.api as sm}
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{gofplots} \PY{k}{as} \PY{n+nn}{smg}

\PY{c+c1}{\PYZsh{}  grÃ¡fico QQPlot}
\PY{n}{fig} \PY{o}{=} \PY{n}{smg}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{residuales}\PY{p}{,} \PY{n}{line}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Mostrar el grÃ¡fico}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_133_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{303}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test de Shapiro\PYZhy{}Wilk para validaciÃ³n de Normalidad en los residuales}

\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k+kn}{import} \PY{n}{stats}

\PY{n}{shapiro\PYZus{}result} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{shapiro}\PY{p}{(}\PY{n}{residuales}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir el resultado del test}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico de Shapiro\PYZhy{}Wilk:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{statistic}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P\PYZhy{}valor:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Interpretar el resultado del test}
\PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}
\PY{k}{if} \PY{n}{shapiro\PYZus{}result}\PY{o}{.}\PY{n}{pvalue} \PY{o}{\PYZgt{}} \PY{n}{alpha}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{No se puede rechazar la hipÃ³tesis nula. Los residuos siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{k}{else}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico de Shapiro-Wilk: 0.9757908607053407
P-valor: 1.0485793225894429e-11
Se rechaza la hipÃ³tesis nula. Los residuos no siguen una distribuciÃ³n normal.
    \end{Verbatim}

    Construimos el modelo con las variables transformadas:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{304}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}

\PY{c+c1}{\PYZsh{} Obtener solo las columnas de df\PYZus{}scaled que deseas graficar}
\PY{n}{variables} \PY{o}{=} \PY{n}{df3}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Iterar sobre las columnas y graficar cada una contra la variable \PYZdq{}Densidad\PYZdq{}}
\PY{k}{for} \PY{n}{column} \PY{o+ow}{in} \PY{n}{variables}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{df3}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{,} \PY{n}{df3}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{n}{column}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Densidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Diagrama de dispersiÃ³n de }\PY{l+s+s1}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{column}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{ vs. }\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{Densidad}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{305}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Modelo Alcohol vs Densidad sin considerar transformaciÃ³n de variable}

\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{X} \PY{o}{=} \PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}   \PY{c+c1}{\PYZsh{} Variable explicativa}
\PY{n}{y} \PY{o}{=} \PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Densidad}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}      \PY{c+c1}{\PYZsh{} Variable objetivo}

\PY{c+c1}{\PYZsh{} Agregar intercepto al conjunto de datos}
\PY{n}{X} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir los resultados del modelo}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:               Densidad   R-squared:                       0.609
Model:                            OLS   Adj. R-squared:                  0.609
Method:                 Least Squares   F-statistic:                     7613.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):               0.00
Time:                        19:33:30   Log-Likelihood:                 23816.
No. Observations:                4898   AIC:                        -4.763e+04
Df Residuals:                    4896   BIC:                        -4.761e+04
Df Model:                           1
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          1.0140      0.000   4407.871      0.000       1.014       1.014
Alcohol       -0.0019   2.17e-05    -87.255      0.000      -0.002      -0.002
==============================================================================
Omnibus:                     4515.647   Durbin-Watson:                   1.745
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1413293.678
Skew:                           3.649   Prob(JB):                         0.00
Kurtosis:                      85.896   Cond. No.                         91.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{306}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Alcohol\PYZus{}inv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{/} \PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Alcohol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{307}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Modelo Alcohol vs Densidad considerando trasnformaciÃ³n de Variable 1/Alcohol}

\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{X} \PY{o}{=} \PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Alcohol\PYZus{}inv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}   \PY{c+c1}{\PYZsh{} Variable explicativa}
\PY{n}{y} \PY{o}{=} \PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Densidad}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}      \PY{c+c1}{\PYZsh{} Variable objetivo}

\PY{c+c1}{\PYZsh{} Agregar intercepto al conjunto de datos}
\PY{n}{X} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{add\PYZus{}constant}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Ajustar el modelo de regresiÃ³n lineal}
\PY{n}{model} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Imprimir los resultados del modelo}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:               Densidad   R-squared:                       0.622
Model:                            OLS   Adj. R-squared:                  0.622
Method:                 Least Squares   F-statistic:                     8043.
Date:                Sun, 28 Apr 2024   Prob (F-statistic):               0.00
Time:                        19:33:30   Log-Likelihood:                 23899.
No. Observations:                4898   AIC:                        -4.779e+04
Df Residuals:                    4896   BIC:                        -4.778e+04
Df Model:                           1
Covariance Type:            nonrobust
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const           0.9731      0.000   4153.950      0.000       0.973       0.974
Alcohol\_inv     0.2166      0.002     89.683      0.000       0.212       0.221
==============================================================================
Omnibus:                     4664.261   Durbin-Watson:                   1.746
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1652083.297
Skew:                           3.832   Prob(JB):                         0.00
Kurtosis:                      92.646   Cond. No.                         92.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    A partir de la transformaciÃ³n realizada la variable ``Alcohol'', se
realiza un anÃ¡lisis comparativo de modelos OLS con, y sin
transformaciÃ³n, de donde se tiene que:

Modelo 1 (sin transformaciÃ³n de la variable `alcohol'):

\(Adj - R^2\): 0.609

Coeficiente para la variable Alcohol: -0.0019

Modelo 2 (transformando la variable `Alcohol'):

\(Adj - R^2\): 0.622 Coeficiente para la variable Alcohol\_inv: 0.2166

El modelo 2 tiene un R-cuadrado ajustado ligeramente mayor (0.622) en
comparaciÃ³n con el modelo 1 (0.609), lo que sugiere que explica una
mayor proporciÃ³n de la variabilidad en la variable de respuesta
(Densidad). AdemÃ¡s, el coeficiente para la variable Alcohol\_inv en el
modelo 2 es significativamente diferente de cero y tiene un efecto
positivo en la variable de respuesta.

Por lo tanto, en base a estos resultados, se podrÃ­a concluir que el
MODELO 2 es mejor en tÃ©rminos de ajuste y explicaciÃ³n de la variabilidad
en la variable de respuesta.

    \hypertarget{ejercicio-de-regresion-lineal-simple}{%
\subsubsection{Ejercicio de regresion lineal
simple}\label{ejercicio-de-regresion-lineal-simple}}

    El ejercicio que nos concierne en este nuevo apartado se refiere a un
conjunto de datos que registra la cantidad de anuncios publicitarios en
redes sociales que realiza una empresa y su correspondiente retorno de
inversiÃ³n en ventas. Se desea determinar si existe una relaciÃ³n lineal
significativa entre la cantidad de anuncios publicitarios y el retorno
de inversiÃ³n.

El dataset nos da informaciÃ³n acerca de los gastos en publicidad (en
miles de dÃ³lares) y las ventas (en miles de unidades) de un producto en
un mercado especÃ­fico:

\begin{itemize}
\tightlist
\item
  \textbf{TV}: Gasto (miles de dÃ³lares) en publicidad en televisiÃ³n.\\
\item
  \textbf{Radio}: Gasto (miles de dÃ³lares) en publicidad en radio.\\
\item
  \textbf{Newspaper}: Gasto (miles de dÃ³lares) en publicidad en
  periÃ³dicos.\\
\item
  \textbf{Sales}: NÃºmero de unidades vendidas (en miles)
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{308}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Cargamos el dataset y entendemos su estructura}

\PY{n}{publicidad} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{D:}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{OneDrive \PYZhy{} Tecnoquimicas}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{99. PERSONAL}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{FormaciÃ³n}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Maestria}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Semestre 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Analisis Cuantitivo}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Trabajo 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{publicidad.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{publicidad}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 200 entries, 0 to 199
Data columns (total 5 columns):
 \#   Column      Non-Null Count  Dtype
---  ------      --------------  -----
 0   Unnamed: 0  200 non-null    int64
 1   TV          200 non-null    float64
 2   Radio       200 non-null    float64
 3   Newspaper   200 non-null    float64
 4   Sales       200 non-null    float64
dtypes: float64(4), int64(1)
memory usage: 7.9 KB
    \end{Verbatim}

    Nos damos cuenta que existe una columna adicional de las declaradas en
el enunciado del ejercicio, con nombre `Unnamed: 0'. Procedemos a llamar
el metodo `head' con el fin de visualizar la estructura del df y quÃ©
datos registra esta columna.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{309}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{publicidad}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{309}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Unnamed: 0     TV  Radio  Newspaper  Sales
0           1  230.1   37.8       69.2   22.1
1           2   44.5   39.3       45.1   10.4
2           3   17.2   45.9       69.3    9.3
3           4  151.5   41.3       58.5   18.5
4           5  180.8   10.8       58.4   12.9
5           6    8.7   48.9       75.0    7.2
6           7   57.5   32.8       23.5   11.8
7           8  120.2   19.6       11.6   13.2
8           9    8.6    2.1        1.0    4.8
9          10  199.8    2.6       21.2   10.6
\end{Verbatim}
\end{tcolorbox}
        
    Al llamar a los primeros 10 registros, nos damos cuenta que la columna
`Unnamed : 0' es un contador de registros que inicia en 1. Sin embargo,
no es relevante para el ejercicio aquÃ­ descrito, por lo que procedemos a
eliminarla.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{310}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{publicidad}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Unnamed: 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,}\PY{n}{inplace}\PY{o}{=} \PY{k+kc}{True}\PY{p}{)} \PY{c+c1}{\PYZsh{} Eliminamos la columna}
\PY{n}{publicidad}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}Revisamos si quedÃ³ grabado}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{310}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
      TV  Radio  Newspaper  Sales
0  230.1   37.8       69.2   22.1
1   44.5   39.3       45.1   10.4
2   17.2   45.9       69.3    9.3
3  151.5   41.3       58.5   18.5
4  180.8   10.8       58.4   12.9
\end{Verbatim}
\end{tcolorbox}
        
    Procedemos a graficar la distribuciÃ³n de las variables y la relaciÃ³n
entre pares:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{311}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Graficas scatter matrix y dimensionamos}
\PY{n}{sn}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{publicidad}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_149_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al graficar la scatter matrix podemos evidenciar que:

\begin{itemize}
\tightlist
\item
  La relaciÃ³n entre el gasto en publicidad en TV vs las Ventas parece de
  dependencia positiva; sin embargo, conforme el gasto en publicidad
  aumenta, parece haber mayor variabilidad de los datos. Nos puede
  inidicar la presencia de heterocedasticidad.
\item
  La relacion entre el gatos en publicidad en Radio vs las Ventas
  tambiÃ©n parece presentar una dependencia positiva como en el apartado
  anterior, aunque mÃ¡s leve y con una mayor dispersiÃ³n en los puntos.
\item
  Entre el gasto en prensa y las ventas no parece haber una dependencia
  notoria, existe una mayor dispersiÃ³n de los datos. No obstante, se
  debe hacer toda la estadÃ­stica para cuantificar las correlaciones
  entre las variables.
\end{itemize}

    De acuerdo a lo anterior, procedemos a calcular el coeficiente de
correlaciÃ³n entre todas las variables y las graficamos mediante un mapa
de calor

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{312}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{plotly}\PY{n+nn}{.}\PY{n+nn}{express} \PY{k}{as} \PY{n+nn}{px}

\PY{n}{corr\PYZus{}matrix} \PY{o}{=} \PY{n}{publicidad}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}Construimos la matriz de correlaciones}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{corr\PYZus{}matrix}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                 TV     Radio  Newspaper     Sales
TV         1.000000  0.054809   0.056648  0.782224
Radio      0.054809  1.000000   0.354104  0.576223
Newspaper  0.056648  0.354104   1.000000  0.228299
Sales      0.782224  0.576223   0.228299  1.000000
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{313}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Graficamos el mapa de calor interactivo}
\PY{n}{fig} \PY{o}{=} \PY{n}{px}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{corr\PYZus{}matrix}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{314}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sn}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{corr\PYZus{}matrix}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mako}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_154_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Teniendo en cuenta los resultados arrojados, podemos corroborar las
afirmaciones anteriores: la variable \textbf{``Sales''} presenta una
relacion directa con las tres variables independientes (\textbf{``TV''},
\textbf{``Radio''}, \textbf{``Newspaper''}), siendo TV la mÃ¡s alta con
una fuerte correlacion de 0.78, seguido de Radio con una correlacion de
0.57 y prensa, con una correlaciÃ³n dÃ©bil de 0.22.

Con el fin de adelantar un modelo de regresiÃ³n simple, y siendo
coherentes con los resultados del punto anterior, planteamos el modelo
donde \textbf{``Sales''} actÃºa como variable dependiente y \textbf{TV}
como variable explicativa, siendo que es la que mayor correlaciÃ³n
presenta. AsÃ­, el modelo:

\[\hat{y} = \hat{\beta_0} + \hat{\beta_1}TV\]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{315}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Corremos el modelo con la interacciÃ³n eliminando la variable categÃ³rica Ind como predictor solo}
\PY{n}{TV} \PY{o}{=} \PY{n}{publicidad}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{VTA} \PY{o}{=} \PY{n}{publicidad}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sales}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{model\PYZus{}pub} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{VTA}\PY{p}{,}\PY{n}{TV}\PY{p}{)}

\PY{n}{results\PYZus{}pub} \PY{o}{=} \PY{n}{model\PYZus{}pub}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{results\PYZus{}pub}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                            OLS Regression Results
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.612
Model:                            OLS   Adj. R-squared:                  0.610
Method:                 Least Squares   F-statistic:                     312.1
Date:                Sun, 28 Apr 2024   Prob (F-statistic):           1.47e-42
Time:                        19:33:33   Log-Likelihood:                -519.05
No. Observations:                 200   AIC:                             1042.
Df Residuals:                     198   BIC:                             1049.
Df Model:                           1
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
TV             0.0475      0.003     17.668      0.000       0.042       0.053
const          7.0326      0.458     15.360      0.000       6.130       7.935
==============================================================================
Omnibus:                        0.531   Durbin-Watson:                   1.935
Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669
Skew:                          -0.089   Prob(JB):                        0.716
Kurtosis:                       2.779   Cond. No.                         338.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
    \end{Verbatim}

    Al correr el modelo se calcula el valor de los coeficientes, que permite
estimar la funciÃ³n de la recta como:

\[\hat{y} = 7.0326 + 0.0475*TV\]

Con un \(R^2\) del 0.612. Es decir, el modelo ajusta a los datos en un
61.2\%, o lo que es lo mismo, el modelo puede explicar el 61.2\% de la
variablidad de la variable respuesta.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{316}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Graficamos la dispersiÃ³n de las variables con la linea de regresiÃ³n}
\PY{n}{sn}\PY{o}{.}\PY{n}{lmplot}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{publicidad}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sales}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{line\PYZus{}kws}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{color}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{palette}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mako}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{aspect}\PY{o}{=}\PY{l+m+mi}{7}\PY{o}{/}\PY{l+m+mi}{4}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{316}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<seaborn.axisgrid.FacetGrid at 0x14d9756ebe0>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_158_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Hemos hecho explicito el modelo de regresiÃ³n que mejor se ajusta a los
datos. Ahora, si quisieramos predecir la venta que generarÃ­an 5 nuevos
anuncios en la TV, Â¿quÃ© nos arrojarÃ­a el modelo? Primero, generemos 5
nuevos datos al azar dentro del rango actual de los datos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{317}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Calculamos las estadÃ­sticas descriptivas de la variable independiente}
\PY{n}{publicidad}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TV}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{317}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
count    200.000000
mean     147.042500
std       85.854236
min        0.700000
25\%       74.375000
50\%      149.750000
75\%      218.825000
max      296.400000
Name: TV, dtype: float64
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{318}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{random}

\PY{c+c1}{\PYZsh{}Genera una lista con numeros al azar dentro del rango del valor minimo y el valor mÃ¡ximo}

\PY{n}{random\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]} \PY{c+c1}{\PYZsh{}lista vacÃ­a}

\PY{c+c1}{\PYZsh{}Itero la generaciÃ³n del nÃºmero al azar y lo guardo en lista}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{x} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.7}\PY{p}{,} \PY{l+m+mf}{296.4}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
    \PY{n}{random\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{n}{random\PYZus{}list}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[175.8, 87.93, 241.36, 175.45, 249.72]
    \end{Verbatim}

    Convertimos el nuevo set de datos en un df para hacer mÃ¡s fÃ¡cil su
lectura y aplicaciÃ³n.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{319}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Se crea un DF a partir de la lista para permitir el cÃ¡lculo}
\PY{n}{tv} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{random\PYZus{}list}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{tv}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{319}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
        0  const
0  175.80      1
1   87.93      1
2  241.36      1
3  175.45      1
4  249.72      1
\end{Verbatim}
\end{tcolorbox}
        
    Generamos los \(\hat{y}\) a partir de los nuevos datos y calculamos el
intervalo de confianza.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{320}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Con la data generada arriba se predicen las siguientes ventas}
\PY{n}{sales\PYZus{}hat} \PY{o}{=} \PY{n}{results\PYZus{}pub}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{tv}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{sales\PYZus{}hat}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
0    15.389535
1    11.212490
2    18.506037
3    15.372897
4    18.903443
dtype: float64
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{321}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Calculamos el intervalo de confianza del 95\PYZpc{}}
\PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{st}
\PY{n}{st}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{n}{df}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{sales\PYZus{}hat}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{sales\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{st}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{sales\PYZus{}hat}\PY{p}{)}\PY{p}{,} \PY{n}{confidence}\PY{o}{=}\PY{l+m+mf}{0.95}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{321}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(12.033705452340925, 19.72005569760285)
\end{Verbatim}
\end{tcolorbox}
        
    De esta manera,si aplicamos el modelo de regresiÃ³n elegido al set de
datos generados en el apartado anterior, se espera que en promedio se
reporten ventas entre el 7.7 y 18.65 unidades con una confianza del
95\%.

    \hypertarget{ejercicio-de-regresiuxf3n-lineal-muxfaltiple}{%
\subsubsection{Ejercicio de regresiÃ³n lineal
mÃºltiple}\label{ejercicio-de-regresiuxf3n-lineal-muxfaltiple}}

Se desea predecir la resistencia a la compresiÃ³n del concreto (Concrete
compressive strength) en funciÃ³n de diferentes variables predictoras
como el cemento (Cement), la escoria (Slag), la ceniza volante (Fly
ash), el agua (Water), el superplastificante (Superplasticizer), el
agregado grueso (Coarse aggregate) y el agregado fino (Fine aggregate).
Para ello se dispone de un conjunto de datos con 1030 observaciones. Se
desea construir un modelo de regresiÃ³n lineal mÃºltiple para predecir la
resistencia a la compresiÃ³n del concreto en funciÃ³n de las variables
predictoras.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{322}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Importar el data set}
\PY{n}{concrete} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{D:}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{OneDrive \PYZhy{} Tecnoquimicas}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{99. PERSONAL}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{FormaciÃ³n}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Maestria}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Semestre 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Analisis Cuantitivo}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Trabajo 1}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{Concrete\PYZus{}Data.xls}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{sheet\PYZus{}name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sheet1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Entender la estructura y caracterÃ­sticas del dataset.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{323}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{concrete}\PY{o}{.}\PY{n}{shape}
\PY{n}{concrete}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1030 entries, 0 to 1029
Data columns (total 9 columns):
 \#   Column                                                 Non-Null Count
Dtype
---  ------                                                 --------------
-----
 0   Cement (component 1)(kg in a m\^{}3 mixture)              1030 non-null
float64
 1   Blast Furnace Slag (component 2)(kg in a m\^{}3 mixture)  1030 non-null
float64
 2   Fly Ash (component 3)(kg in a m\^{}3 mixture)             1030 non-null
float64
 3   Water  (component 4)(kg in a m\^{}3 mixture)              1030 non-null
float64
 4   Superplasticizer (component 5)(kg in a m\^{}3 mixture)    1030 non-null
float64
 5   Coarse Aggregate  (component 6)(kg in a m\^{}3 mixture)   1030 non-null
float64
 6   Fine Aggregate (component 7)(kg in a m\^{}3 mixture)      1030 non-null
float64
 7   Age (day)                                              1030 non-null
int64
 8   Concrete compressive strength(MPa, megapascals)        1030 non-null
float64
dtypes: float64(8), int64(1)
memory usage: 72.5 KB
    \end{Verbatim}

    Con el fin de simplificar el ejercicio, procedemos a renombrar las
columnas.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{324}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{headers} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cement}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Blast Furnace Slag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fly Ash}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Superplasticizer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coarse Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fine Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{concrete}\PY{o}{.}\PY{n}{columns} \PY{o}{=} \PY{n}{headers}
\PY{n}{concrete}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{324}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \textbackslash{}
0   540.0                 0.0      0.0  162.0               2.5
1   540.0                 0.0      0.0  162.0               2.5
2   332.5               142.5      0.0  228.0               0.0
3   332.5               142.5      0.0  228.0               0.0
4   198.6               132.4      0.0  192.0               0.0

   Coarse Aggregate  Fine Aggregate  Age  Concrete Compressive Strength
0            1040.0           676.0   28                      79.986111
1            1055.0           676.0   28                      61.887366
2             932.0           594.0  270                      40.269535
3             932.0           594.0  365                      41.052780
4             978.4           825.5  360                      44.296075
\end{Verbatim}
\end{tcolorbox}
        
    Aprovechamos para graficar la distribuciÃ³n de las variables y su
relaciÃ³n entre pares a travÃ©s de una scatter matrix.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{325}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Graficas scatter matrix y dimensionamos}
\PY{n}{sn}\PY{o}{.}\PY{n}{pairplot}\PY{p}{(}\PY{n}{concrete}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{325}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<seaborn.axisgrid.PairGrid at 0x14d99192520>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_175_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    La anterior grafica nos permite evidenciar:

\begin{itemize}
\item
  La variable dependiente \textbf{`Cement Compressive Strength'} parece
  tener una relaciÃ³n de dependencia positiva con las variables
  \textbf{`Cement'} y \textbf{`Superplasticizer'}, y una dependencia
  negativa con la variable \textbf{`Water'}. La relacion de dependencia
  de \textbf{`Cement Compressive Strength'} con las demÃ¡s variables no
  es tan aparente, por lo que debemos calcular la metrica de
  correlaciones para conocer la fuerza de esa relaciÃ³n.
\item
  Algunos de los atributos muestran cierta relaciÃ³n de dependencia:
  \textbf{`Water'} \& \textbf{`Superplasticizer'} parecen tener una
  relaciÃ³n de dependencia negativa, asÃ­ como la primera con
  \textbf{`Coarse Agregate'}. Para la relaciÃ³n de las demÃ¡s variables
  independientes no podemos acercarnos a una conclusiÃ³n sin calcular la
  matriz de correlaciÃ³n que se propone en el punto anterior.
\end{itemize}

Por lo mismo, procedemos a generar una matriz de correlaciÃ³n y el
respectivo grÃ¡fico de mapa de calor:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{326}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{corr\PYZus{}concrete} \PY{o}{=} \PY{n}{concrete}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{}Construimos la matriz de correlaciones}
\PY{n}{corr\PYZus{}concrete}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{326}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                                 Cement  Blast Furnace Slag   Fly Ash  \textbackslash{}
Cement                         1.000000           -0.275193 -0.397475
Blast Furnace Slag            -0.275193            1.000000 -0.323569
Fly Ash                       -0.397475           -0.323569  1.000000
Water                         -0.081544            0.107286 -0.257044
Superplasticizer               0.092771            0.043376  0.377340
Coarse Aggregate              -0.109356           -0.283998 -0.009977
Fine Aggregate                -0.222720           -0.281593  0.079076
Age                            0.081947           -0.044246 -0.154370
Concrete Compressive Strength  0.497833            0.134824 -0.105753

                                  Water  Superplasticizer  Coarse Aggregate  \textbackslash{}
Cement                        -0.081544          0.092771         -0.109356
Blast Furnace Slag             0.107286          0.043376         -0.283998
Fly Ash                       -0.257044          0.377340         -0.009977
Water                          1.000000         -0.657464         -0.182312
Superplasticizer              -0.657464          1.000000         -0.266303
Coarse Aggregate              -0.182312         -0.266303          1.000000
Fine Aggregate                -0.450635          0.222501         -0.178506
Age                            0.277604         -0.192717         -0.003016
Concrete Compressive Strength -0.289613          0.366102         -0.164928

                               Fine Aggregate       Age  \textbackslash{}
Cement                              -0.222720  0.081947
Blast Furnace Slag                  -0.281593 -0.044246
Fly Ash                              0.079076 -0.154370
Water                               -0.450635  0.277604
Superplasticizer                     0.222501 -0.192717
Coarse Aggregate                    -0.178506 -0.003016
Fine Aggregate                       1.000000 -0.156094
Age                                 -0.156094  1.000000
Concrete Compressive Strength       -0.167249  0.328877

                               Concrete Compressive Strength
Cement                                              0.497833
Blast Furnace Slag                                  0.134824
Fly Ash                                            -0.105753
Water                                              -0.289613
Superplasticizer                                    0.366102
Coarse Aggregate                                   -0.164928
Fine Aggregate                                     -0.167249
Age                                                 0.328877
Concrete Compressive Strength                       1.000000
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{327}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Graficamos el mapa de calor interactivo}
\PY{n}{fig} \PY{o}{=} \PY{n}{px}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{corr\PYZus{}concrete}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{328}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sn}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{corr\PYZus{}concrete}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mako}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_179_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    El apartado anterior nos permite corroborar lo inferido en la grafica de
\emph{scatter matrix}:

\begin{itemize}
\tightlist
\item
  La variable dependiente \textbf{`Concrete Compressive Strength'} en
  efecto presenta una relaciÃ³n de dependencia positiva moderada de 0.49
  con el componente 1 \textbf{`Concrete'} y dependencia dÃ©bil de 0.36
  con \textbf{`Superplasticizer'}, asÃ­ como con \textbf{`Age'} con un
  0.32 de correlaciÃ³n. AdemÃ¡s, presenta una relaciÃ³n de dependencia
  negativa con la variable \textbf{`Water'} de 0.28. Presenta una
  relaciÃ³n de dependencia debil con los demÃ¡s atributos.
\end{itemize}

    Una vez conocemos la relaciÃ³n entre las variables, proponemos un modelo
de regresiÃ³n mÃºltiple que iremos refinando conforme identificamos las
variables significativas.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{329}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X} \PY{o}{=} \PY{n}{concrete}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{Y} \PY{o}{=} \PY{n}{concrete}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{mod} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{Y}\PY{p}{,}\PY{n}{X}\PY{p}{)}
\PY{n}{mod\PYZus{}results} \PY{o}{=} \PY{n}{mod}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                                  OLS Regression Results
================================================================================
=========
Dep. Variable:     Concrete Compressive Strength   R-squared:
0.615
Model:                                       OLS   Adj. R-squared:
0.612
Method:                            Least Squares   F-statistic:
204.3
Date:                           Sun, 28 Apr 2024   Prob (F-statistic):
6.76e-206
Time:                                   19:33:46   Log-Likelihood:
-3869.0
No. Observations:                           1030   AIC:
7756.
Df Residuals:                               1021   BIC:
7800.
Df Model:                                      8
Covariance Type:                       nonrobust
================================================================================
======
                         coef    std err          t      P>|t|      [0.025
0.975]
--------------------------------------------------------------------------------
------
Cement                 0.1198      0.008     14.110      0.000       0.103
0.136
Blast Furnace Slag     0.1038      0.010     10.245      0.000       0.084
0.124
Fly Ash                0.0879      0.013      6.988      0.000       0.063
0.113
Water                 -0.1503      0.040     -3.741      0.000      -0.229
-0.071
Superplasticizer       0.2907      0.093      3.110      0.002       0.107
0.474
Coarse Aggregate       0.0180      0.009      1.919      0.055      -0.000
0.036
Fine Aggregate         0.0202      0.011      1.883      0.060      -0.001
0.041
Age                    0.1142      0.005     21.046      0.000       0.104
0.125
const                -23.1638     26.588     -0.871      0.384     -75.338
29.010
==============================================================================
Omnibus:                        5.379   Durbin-Watson:                   1.281
Prob(Omnibus):                  0.068   Jarque-Bera (JB):                5.305
Skew:                          -0.174   Prob(JB):                       0.0705
Kurtosis:                       3.045   Cond. No.                     1.06e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
[2] The condition number is large, 1.06e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
    \end{Verbatim}

    Al correr el modelo, vemos que las variables \textbf{`Coarse Aggregate'}
\& \textbf{`Fine Aggregate'} arrojan un p-valor mayor a 0.05, por lo que
podrÃ­amos descartarlas al no ser significativas para el modelo. Corremos
nuevamente el modelo, deshaciendonos de ambas variables. El modelo se
ajusta un 61.2\% a los datos, o lo que es lo mismo, explica el 61\% de
la variabilidad de los datos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{330}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X} \PY{o}{=} \PY{n}{concrete}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coarse Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fine Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{Y} \PY{o}{=} \PY{n}{concrete}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{mod} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{OLS}\PY{p}{(}\PY{n}{Y}\PY{p}{,}\PY{n}{X}\PY{p}{)}
\PY{n}{mod\PYZus{}results} \PY{o}{=} \PY{n}{mod}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                                  OLS Regression Results
================================================================================
=========
Dep. Variable:     Concrete Compressive Strength   R-squared:
0.614
Model:                                       OLS   Adj. R-squared:
0.612
Method:                            Least Squares   F-statistic:
271.2
Date:                           Sun, 28 Apr 2024   Prob (F-statistic):
1.78e-207
Time:                                   19:33:47   Log-Likelihood:
-3871.0
No. Observations:                           1030   AIC:
7756.
Df Residuals:                               1023   BIC:
7791.
Df Model:                                      6
Covariance Type:                       nonrobust
================================================================================
======
                         coef    std err          t      P>|t|      [0.025
0.975]
--------------------------------------------------------------------------------
------
Cement                 0.1054      0.004     24.821      0.000       0.097
0.114
Blast Furnace Slag     0.0865      0.005     17.386      0.000       0.077
0.096
Fly Ash                0.0687      0.008      8.881      0.000       0.054
0.084
Water                 -0.2183      0.021    -10.332      0.000      -0.260
-0.177
Superplasticizer       0.2390      0.085      2.826      0.005       0.073
0.405
Age                    0.1135      0.005     20.987      0.000       0.103
0.124
const                 29.0302      4.212      6.891      0.000      20.764
37.296
==============================================================================
Omnibus:                        5.233   Durbin-Watson:                   1.286
Prob(Omnibus):                  0.073   Jarque-Bera (JB):                5.193
Skew:                          -0.174   Prob(JB):                       0.0745
Kurtosis:                       3.019   Cond. No.                     4.66e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
[2] The condition number is large, 4.66e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
    \end{Verbatim}

    Al eliminar las variables \textbf{`Coarse Aggregate'} \& \textbf{`Fine
Aggregate'} vemos que los demÃ¡s atributos se mantienen significativos;
sin embargo, el \(Adj. R^2\) no mejora, indicandonos que estas variables
no aÃ±adÃ­an distorsiÃ³n adicional al modelo ni explicaban parte de la
variabilidad de los datos.

No obstante, al usar los criterios de informaciÃ³n podemos comparar ambos
modelos y discernir sobre su calidad: el criterio de Akaike no muestra
una mejora, sin embargo, el criterio de Bayes presenta una mejorÃ­a en el
segundo modelo, pasando de 7800 a 7791. Podemos asÃ­ concluir que el
segundo modelo, donde todas las variables son significativas y presenta
un ajuste del 61.2\%, es relativamente de mejor calidad que el primer
modelo, donde se usan todas los atributos disponibles.

    \hypertarget{validacion-de-supuestos-del-modelo}{%
\paragraph{Validacion de supuestos del
modelo}\label{validacion-de-supuestos-del-modelo}}

Una vez planteado el modelo, procedemos a validar cada uno de los
supuestos del modelo,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Iniciamos con la validaciÃ³n de la independencia de los errores.
  Adelantamos el anÃ¡lisis grÃ¡fico con correlogramas, seguido de las
  pruebas formales.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{331}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{graphics}\PY{n+nn}{.}\PY{n+nn}{tsaplots} \PY{k+kn}{import} \PY{n}{plot\PYZus{}acf}\PY{p}{,} \PY{n}{plot\PYZus{}pacf}

\PY{c+c1}{\PYZsh{} Test 1}
\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}

\PY{n}{plot\PYZus{}acf}\PY{p}{(}\PY{n}{Y}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{lags}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ACF de la la fuerza de compresiÃ³n del concreto}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}
\PY{n}{plot\PYZus{}pacf}\PY{p}{(}\PY{n}{Y}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{lags}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PACF de la fuerza de compresiÃ³n del concreto}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}

\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{1.2}\PY{p}{]}\PY{p}{)}
\PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{1.2}\PY{p}{]}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{subplots\PYZus{}adjust}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_187_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al construir el grafico de autocorrelaciÃ³n simple y autocorrelaciÃ³n
parcial de la variable dependiente, aparentemente vemos que, con un lag
de 5 datos, cada uno de ellos es significativo y nos llevarÃ­a a pensar
que no existe independencia de los errores. AdemÃ¡s, al correr el modelo
nos arroja un valor de Durbin - Watson de 1.286, alejado del 2 ideal, lo
que nos reforzarÃ­a la idea de autocorrelaciÃ³n.

Corremos la prueba de Breusch - Godfrey definiendo el mÃ©todo y
presentando una tabla de validaciÃ³n de hipÃ³tesis, que se definen asÃ­:

\[ H_0: \rho(\epsilon_{i}, \epsilon_{i+1}) = 0 \\
H_1: \rho(\epsilon_{i}, \epsilon_{i+1}) \neq 0 \]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{332}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{stats}\PY{n+nn}{.}\PY{n+nn}{diagnostic} \PY{k+kn}{import} \PY{n}{acorr\PYZus{}breusch\PYZus{}godfrey}\PY{p}{,} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{,} \PY{n}{het\PYZus{}white}

\PY{c+c1}{\PYZsh{} Test 3}
\PY{k}{def} \PY{n+nf}{test\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{model\PYZus{}results}\PY{p}{,} \PY{n}{maxlags}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{list} \PY{o}{=} \PY{p}{[}\PY{p}{]}

    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{maxlags}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        \PY{n}{values} \PY{o}{=} \PY{n}{acorr\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{model\PYZus{}results}\PY{p}{,} \PY{n}{nlags}\PY{o}{=}\PY{n}{i}\PY{p}{)}
        \PY{n+nb}{list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{values}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
    
    \PY{n}{table} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n+nb}{list}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lags}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{table}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lags}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} P\PYZhy{}value \PYZlt{} pvalue }
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.1}
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.05}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.05}
    \PY{n}{table}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pv\PYZlt{}0.01}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{l+m+mf}{0.01}

    \PY{c+c1}{\PYZsh{} Rounding}
    \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{table}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pvalue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

    \PY{k}{return} \PY{n}{table}


\PY{c+c1}{\PYZsh{} La hipotesis nula es de no autocorrelacion}
\PY{c+c1}{\PYZsh{} Se rechaza la no autocorrelacion hasta 5 rezagos. }
\PY{n}{test\PYZus{}breusch\PYZus{}godfrey}\PY{p}{(}\PY{n}{mod\PYZus{}results}\PY{p}{,} \PY{n}{maxlags}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{332}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
           LM  pvalue  pv<0.1  pv<0.05  pv<0.01
lags
1     131.737     0.0    True     True     True
2     138.174     0.0    True     True     True
3     143.549     0.0    True     True     True
4     170.467     0.0    True     True     True
5     215.916     0.0    True     True     True
\end{Verbatim}
\end{tcolorbox}
        
    Al correr el test de Breusch - Godfrey hasta en 5 rezagos podemos
rechazar la hipÃ³tesis nula y concluir que los errores no son
independiente, existe \textbf{autocorrelaciÃ³n}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Continuamos con validaciÃ³n de la varianza constante de los errores. Al
  igual que en el apartado pasado, iniciamos con una anÃ¡lisis grÃ¡fico y
  procedemos a correr las pruebas formales.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{333}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Test grÃ¡fico}
\PY{n}{y\PYZus{}hat} \PY{o}{=} \PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}
\PY{n}{residuos} \PY{o}{=} \PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{resid}

\PY{n}{sn}\PY{o}{.}\PY{n}{scatterplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{y\PYZus{}hat}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{residuos}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Analisis grafico de los residuos}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Fuerza de compresiÃ³n del concreto}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Residuo}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{333}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Text(0, 0.5, 'Residuo')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_191_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al graficar el comportamiento de las predicciones con los errores no es
muy claro si existe homocedasticidad; sin embargo, conforme aumenta la
variable y los errores se ven mÃ¡s dipersos. Por lo mismo, adelantamos
las pruebas formales de Breusch - Pagan y White con el fin de corroborar
si existe o no heterocedasticidad. Por lo mismo, planteamos la prueba de
hipÃ³tesis:

\[ H_0: \mathbb{V}(\epsilon_{i}) = Constante \\
H_1: \mathbb{V}(\epsilon_{i})  \neq Constante \]

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{334}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Test 2}
\PY{n}{BP\PYZus{}test} \PY{o}{=} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{(}\PY{n}{residuos}\PY{p}{,} \PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{BP\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{BP\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{El estadistico Breusch \PYZhy{} Pagan es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ y el p\PYZhy{}value es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}test}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
El estadistico Breusch - Pagan es 139.182 y el p-value es 0.0
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{335}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test 3}
\PY{n}{white\PYZus{}test} \PY{o}{=} \PY{n}{het\PYZus{}white}\PY{p}{(}\PY{n}{residuos}\PY{p}{,} \PY{n}{mod\PYZus{}results}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EstadÃ­stico White}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Statistic}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Test p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{white\PYZus{}test} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{white\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{white\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'EstadÃ­stico White': 258.69, 'p-value': 0.0, 'F-Statistic': 12.447, 'F-Test
p-value': 0.0\}
    \end{Verbatim}

    Ambas pruebas nos dan un p-value menor a 0.05, lo que nos lleva a
rechazar la hipÃ³tesis nula y concluir que \textbf{el modelo presenta
heterocedasticidad}, es decir, la varianza de los errores no es
constante.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Ahora, procedemos a probar si los datos se distribuyen o no de manera
  normal con las dos pruebas de bondad de ajuste de D'Angostino y Jarque
  Bera.
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{336}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{statsmodels}\PY{n+nn}{.}\PY{n+nn}{api} \PY{k}{as} \PY{n+nn}{sm}

\PY{c+c1}{\PYZsh{}Test grÃ¡fico de normalidad}
\PY{n}{figure} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{qqplot}\PY{p}{(}\PY{n}{residuos}\PY{p}{,} \PY{n}{line} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{gcf}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}size\PYZus{}inches}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_196_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Al graficar los residuos, no nos da informaciÃ³n aparente para descartar
la normalidad de los residuos. AdemÃ¡s, el p-valor de la prueba Jarque
Bera es mayor a 0.05, lo que no nos da informaciÃ³n suficiente para
rechazar la hipÃ³tesis nula ni descartar la distribuciÃ³n normal de los
residuos. Sin embargo, procedemos con el test D'Angostino

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{337}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k+kn}{import} \PY{n}{normaltest}

\PY{c+c1}{\PYZsh{}Test 2 de bondad de ajuste}
\PY{n}{k2}\PY{p}{,} \PY{n}{p\PYZus{}value} \PY{o}{=} \PY{n}{normaltest}\PY{p}{(}\PY{n}{residuos}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{EstadÃ­stico = }\PY{l+s+si}{\PYZob{}}\PY{n}{k2}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, p\PYZhy{}value = }\PY{l+s+si}{\PYZob{}}\PY{n}{p\PYZus{}value}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
EstadÃ­stico = 5.233211197298024, p-value = 0.0730504048541871
    \end{Verbatim}

    Como vemos con el test de Jarque - Bera, el p - valor de la prueba de
D'Angostino estÃ¡ por encima del 0.05, lo que conlleva a aceptar la
hipÃ³tesis nula de normalidad de los residuos.

Ahora, hecha la validad de los supuestos, podemos plantearnos correr un
modelo robusto como MÃ­nimos Cuadrados Generalizados y revisar si esto
nos corrige los errores aquÃ­ presentados, principalmente la
heterocedasticidad.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{338}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}r} \PY{o}{=} \PY{n}{concrete}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Coarse Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Fine Aggregate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{const}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{y\PYZus{}r} \PY{o}{=} \PY{n}{concrete}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Concrete Compressive Strength}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{model\PYZus{}r} \PY{o}{=} \PY{n}{sm}\PY{o}{.}\PY{n}{GLS}\PY{p}{(}\PY{n}{y\PYZus{}r}\PY{p}{,} \PY{n}{X\PYZus{}r}\PY{p}{)}
\PY{n}{res} \PY{o}{=} \PY{n}{model\PYZus{}r}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{res}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                                  GLS Regression Results
================================================================================
=========
Dep. Variable:     Concrete Compressive Strength   R-squared:
0.614
Model:                                       GLS   Adj. R-squared:
0.612
Method:                            Least Squares   F-statistic:
271.2
Date:                           Sun, 28 Apr 2024   Prob (F-statistic):
1.78e-207
Time:                                   19:33:47   Log-Likelihood:
-3871.0
No. Observations:                           1030   AIC:
7756.
Df Residuals:                               1023   BIC:
7791.
Df Model:                                      6
Covariance Type:                       nonrobust
================================================================================
======
                         coef    std err          t      P>|t|      [0.025
0.975]
--------------------------------------------------------------------------------
------
Cement                 0.1054      0.004     24.821      0.000       0.097
0.114
Blast Furnace Slag     0.0865      0.005     17.386      0.000       0.077
0.096
Fly Ash                0.0687      0.008      8.881      0.000       0.054
0.084
Water                 -0.2183      0.021    -10.332      0.000      -0.260
-0.177
Superplasticizer       0.2390      0.085      2.826      0.005       0.073
0.405
Age                    0.1135      0.005     20.987      0.000       0.103
0.124
const                 29.0302      4.212      6.891      0.000      20.764
37.296
==============================================================================
Omnibus:                        5.233   Durbin-Watson:                   1.286
Prob(Omnibus):                  0.073   Jarque-Bera (JB):                5.193
Skew:                          -0.174   Prob(JB):                       0.0745
Kurtosis:                       3.019   Cond. No.                     4.66e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly
specified.
[2] The condition number is large, 4.66e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
    \end{Verbatim}

    Al correr los mÃ­nimos cuadrados generalizados vemos que los estadÃ­sticos
del modelo no cambian:

\$ Adj - R\^{}2 = 0.612 \$ Lo que implica que el modelo no ajusta mejor
la variaciÃ³n de los datos. El modelo sigue siendo significativo para
explicar el comportamiento de la variable dependiente, pero los
criterios de infromaciÃ³n de Akaike no mejoran, lo que significa que este
modelo no es mejor al planteado en el apartado anterior.

En cuanto a los supuestos sobre el modelo, vemos que la mÃ©trica de
Durbin - Watson no se modifica, lo que implica que GLS no logra corregir
el problema de acutocorrelaciÃ³n. Se sigue cumpliendo Jarque - Bera.
Corremos las pruebas para Breusch - Pagan y White para validar
homocedasticidad.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{339}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{resid\PYZus{}r} \PY{o}{=} \PY{n}{res}\PY{o}{.}\PY{n}{resid}
\PY{c+c1}{\PYZsh{} Test 2}
\PY{n}{BP\PYZus{}r} \PY{o}{=} \PY{n}{het\PYZus{}breuschpagan}\PY{p}{(}\PY{n}{resid\PYZus{}r}\PY{p}{,} \PY{n}{res}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{BP\PYZus{}r} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{BP\PYZus{}r}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{El estadistico Breusch \PYZhy{} Pagan es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}r}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ y el p\PYZhy{}value es }\PY{l+s+si}{\PYZob{}}\PY{n}{BP\PYZus{}r}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
El estadistico Breusch - Pagan es 139.182 y el p-value es 0.0
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{340}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Test 3}
\PY{n}{white\PYZus{}test\PYZus{}r} \PY{o}{=} \PY{n}{het\PYZus{}white}\PY{p}{(}\PY{n}{resid\PYZus{}r}\PY{p}{,} \PY{n}{res}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{exog}\PY{p}{)}
\PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EstadÃ­stico White}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Statistic}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F\PYZhy{}Test p\PYZhy{}value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{white\PYZus{}test\PYZus{}r} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{n}{white\PYZus{}test\PYZus{}r}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} H0: homocedasticidad en los errores}
\PY{c+c1}{\PYZsh{} H1: heterocedasticiadad en los erroes}

\PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{white\PYZus{}test\PYZus{}r}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
\{'EstadÃ­stico White': 258.69, 'p-value': 0.0, 'F-Statistic': 12.447, 'F-Test
p-value': 0.0\}
    \end{Verbatim}

    A pesar de correr el modelo generalizado, evidenciamos que ambas pruebas
nos dan un p-value menor a 0.05, lo que nos lleva nuevamente a rechazar
la hipÃ³tesis nula y concluir que \textbf{el modelo presenta
heterocedasticidad}, es decir, la varianza de los errores no es
constante.


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
